{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(proportion=0.1):\n",
    "    dir_name = \"train_set\"\n",
    "    file_list = os.listdir(dir_name)\n",
    "    l = len(file_list)\n",
    "    n = int(proportion * l)\n",
    "    data_list = []\n",
    "    for i in range(n):\n",
    "        path = os.path.join(dir_name, file_list[i])\n",
    "        data_list.append(pd.read_csv(path))\n",
    "    return pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "df_raw = load_data(proportion=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell Index</th>\n",
       "      <th>Cell X</th>\n",
       "      <th>Cell Y</th>\n",
       "      <th>Height</th>\n",
       "      <th>Azimuth</th>\n",
       "      <th>Electrical Downtilt</th>\n",
       "      <th>Mechanical Downtilt</th>\n",
       "      <th>Frequency Band</th>\n",
       "      <th>RS Power</th>\n",
       "      <th>Cell Altitude</th>\n",
       "      <th>Cell Building Height</th>\n",
       "      <th>Cell Clutter Index</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Building Height</th>\n",
       "      <th>Clutter Index</th>\n",
       "      <th>RSRP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001701</td>\n",
       "      <td>424515.0</td>\n",
       "      <td>3376325.0</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>424050</td>\n",
       "      <td>3376785</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>-102.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001701</td>\n",
       "      <td>424515.0</td>\n",
       "      <td>3376325.0</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>424055</td>\n",
       "      <td>3376790</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>-100.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001701</td>\n",
       "      <td>424515.0</td>\n",
       "      <td>3376325.0</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>424545</td>\n",
       "      <td>3376390</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-70.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001701</td>\n",
       "      <td>424515.0</td>\n",
       "      <td>3376325.0</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>424565</td>\n",
       "      <td>3376410</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-65.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001701</td>\n",
       "      <td>424515.0</td>\n",
       "      <td>3376325.0</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>424560</td>\n",
       "      <td>3376405</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-64.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1001701</td>\n",
       "      <td>424515.0</td>\n",
       "      <td>3376325.0</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>424520</td>\n",
       "      <td>3376365</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-75.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1001701</td>\n",
       "      <td>424515.0</td>\n",
       "      <td>3376325.0</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>424570</td>\n",
       "      <td>3376415</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-67.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1001701</td>\n",
       "      <td>424515.0</td>\n",
       "      <td>3376325.0</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>424495</td>\n",
       "      <td>3376340</td>\n",
       "      <td>505</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-78.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1001701</td>\n",
       "      <td>424515.0</td>\n",
       "      <td>3376325.0</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>424505</td>\n",
       "      <td>3376350</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-72.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1001701</td>\n",
       "      <td>424515.0</td>\n",
       "      <td>3376325.0</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>424485</td>\n",
       "      <td>3376330</td>\n",
       "      <td>505</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-75.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cell Index    Cell X     Cell Y  Height  Azimuth  Electrical Downtilt  \\\n",
       "0     1001701  424515.0  3376325.0      24      300                    6   \n",
       "1     1001701  424515.0  3376325.0      24      300                    6   \n",
       "2     1001701  424515.0  3376325.0      24      300                    6   \n",
       "3     1001701  424515.0  3376325.0      24      300                    6   \n",
       "4     1001701  424515.0  3376325.0      24      300                    6   \n",
       "5     1001701  424515.0  3376325.0      24      300                    6   \n",
       "6     1001701  424515.0  3376325.0      24      300                    6   \n",
       "7     1001701  424515.0  3376325.0      24      300                    6   \n",
       "8     1001701  424515.0  3376325.0      24      300                    6   \n",
       "9     1001701  424515.0  3376325.0      24      300                    6   \n",
       "\n",
       "   Mechanical Downtilt  Frequency Band  RS Power  Cell Altitude  \\\n",
       "0                    3          2585.0      16.2            504   \n",
       "1                    3          2585.0      16.2            504   \n",
       "2                    3          2585.0      16.2            504   \n",
       "3                    3          2585.0      16.2            504   \n",
       "4                    3          2585.0      16.2            504   \n",
       "5                    3          2585.0      16.2            504   \n",
       "6                    3          2585.0      16.2            504   \n",
       "7                    3          2585.0      16.2            504   \n",
       "8                    3          2585.0      16.2            504   \n",
       "9                    3          2585.0      16.2            504   \n",
       "\n",
       "   Cell Building Height  Cell Clutter Index       X        Y  Altitude  \\\n",
       "0                     0                   5  424050  3376785       496   \n",
       "1                     0                   5  424055  3376790       496   \n",
       "2                     0                   5  424545  3376390       504   \n",
       "3                     0                   5  424565  3376410       504   \n",
       "4                     0                   5  424560  3376405       504   \n",
       "5                     0                   5  424520  3376365       504   \n",
       "6                     0                   5  424570  3376415       504   \n",
       "7                     0                   5  424495  3376340       505   \n",
       "8                     0                   5  424505  3376350       504   \n",
       "9                     0                   5  424485  3376330       505   \n",
       "\n",
       "   Building Height  Clutter Index    RSRP  \n",
       "0                0             15 -102.20  \n",
       "1                0             15 -100.75  \n",
       "2                0              5  -70.20  \n",
       "3                0              5  -65.25  \n",
       "4                0              5  -64.20  \n",
       "5                0              5  -75.33  \n",
       "6                0              5  -67.44  \n",
       "7                0              5  -78.57  \n",
       "8                0              5  -72.63  \n",
       "9                0              5  -75.25  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame()\n",
    "epsilon = 1e-20\n",
    "# 发射机功率\n",
    "df_features[\"RS Power\"] = df_raw[\"RS Power\"]\n",
    "# 发射机中心频率\n",
    "df_features[\"log frequency band\"] = np.log(df_raw[\"Frequency Band\"] + epsilon)\n",
    "# 发射机相对高度\n",
    "tmp_h = df_raw[\"Height\"] + df_raw[\"Cell Altitude\"] - df_raw[\"Altitude\"]\n",
    "tmp_h[tmp_h < 0] = 0\n",
    "df_features[\"log hb\"] = np.log(tmp_h + epsilon)\n",
    "# 链路距离\n",
    "tmp_d = np.sqrt(np.square(df_raw[\"Cell X\"] - df_raw[\"X\"]) + np.square(df_raw[\"Cell Y\"] - df_raw[\"Y\"]))\n",
    "df_features[\"log d\"] = np.log(tmp_d + epsilon)\n",
    "# 发射机相对高度 * 链路距离\n",
    "df_features[\"log hb * log d\"] = df_features[\"log hb\"] * df_features[\"log d\"]\n",
    "# 栅格与信号线相对高度\n",
    "sum_downtilt_rad = np.deg2rad(df_raw[\"Electrical Downtilt\"] + df_raw[\"Mechanical Downtilt\"]) # 转成弧度\n",
    "df_features[\"log delta_hv\"] = np.log(np.abs(tmp_h - np.multiply(np.tan(sum_downtilt_rad), tmp_d)) + epsilon) # 往上往下是一样的\n",
    "# cos(接收位置与信号线的夹角2d)\n",
    "df_features[\"cos diff angle 2d\"] = np.cos(\n",
    "    np.arctan((df_raw['X'] - df_raw['Cell X']) / (df_raw['Y'] - df_raw['Cell Y'] + epsilon))\n",
    "    - np.deg2rad(df_raw['Azimuth']))\n",
    "# sin(接收位置与信号线的夹角2d)\n",
    "df_features[\"sin diff angle 2d\"] = np.sin(\n",
    "    np.arctan((df_raw['X'] - df_raw['Cell X']) / (df_raw['Y'] - df_raw['Cell Y'] + epsilon))\n",
    "    - np.deg2rad(df_raw['Azimuth']))\n",
    "\n",
    "# 信号线向量\n",
    "tmp_vec1 = np.concatenate([\n",
    "    np.multiply(np.cos(np.array(sum_downtilt_rad)), np.array(df_features[\"sin diff angle 2d\"])).reshape(-1, 1),\n",
    "    np.multiply(np.cos(np.array(sum_downtilt_rad)), np.array(df_features[\"cos diff angle 2d\"])).reshape(-1, 1),\n",
    "    -np.sin(np.array(sum_downtilt_rad)).reshape(-1, 1)],\n",
    "    axis=1)\n",
    "# 接收处与发射台向量\n",
    "tmp_vec2 = np.concatenate([\n",
    "    np.array(df_raw['X'] - df_raw['Cell X']).reshape(-1, 1),\n",
    "    np.array(df_raw['Y'] - df_raw['Cell Y']).reshape(-1, 1),\n",
    "    -np.array(tmp_h).reshape(-1, 1)],\n",
    "    axis=1)\n",
    "\n",
    "# cos(接收位置与信号线的夹角3d)\n",
    "df_features[\"cos diff angle 3d\"] = np.sum(np.multiply(tmp_vec1, tmp_vec2), axis=1)/(np.linalg.norm(tmp_vec2, axis=1) + epsilon)\n",
    "# sin(接收位置与信号线的夹角3d)\n",
    "tmp_sin_square = 1-np.square(df_features[\"cos diff angle 3d\"])\n",
    "tmp_sin_square[tmp_sin_square<0] = 0\n",
    "df_features[\"sin diff angle 3d\"] = np.sqrt(tmp_sin_square)\n",
    "\n",
    "# 发射处遮挡建筑物高度\n",
    "df_features[\"log Cell Building Height\"] = np.log(df_raw[\"Cell Building Height\"] + epsilon)\n",
    "# 接收处遮挡建筑物高度\n",
    "df_features[\"log Building Height\"] = np.log(df_raw[\"Building Height\"] + epsilon)\n",
    "\n",
    "# 建筑物覆盖密度（接收处数量/面积）\n",
    "cell_indices = np.unique(df_raw[\"Cell Index\"])\n",
    "l = df_raw.shape[0]\n",
    "density = np.zeros(l)\n",
    "for cell_index in cell_indices:\n",
    "    tmp_cell = df_raw[df_raw[\"Cell Index\"]==cell_index]\n",
    "    num_receivers = tmp_cell.shape[0]\n",
    "    surface = (np.max(tmp_cell[\"X\"]) - np.min(tmp_cell[\"X\"]))\\\n",
    "            * (np.max(tmp_cell[\"Y\"]) - np.min(tmp_cell[\"Y\"]))\n",
    "    density[df_raw[\"Cell Index\"]==cell_index] = num_receivers/surface\n",
    "    \n",
    "df_features[\"density\"] = density\n",
    "\n",
    "# 发射处/接收处地物类型\n",
    "onehot_encoder = preprocessing.OneHotEncoder()\n",
    "categorical_features = np.concatenate([np.array(df_raw[\"Cell Clutter Index\"]).reshape(-1, 1),\n",
    "                                       np.array(df_raw[\"Clutter Index\"]).reshape(-1, 1)], axis=1)\n",
    "\n",
    "onehot_encoder = preprocessing.OneHotEncoder(categories=[list(range(1, 21)), list(range(1, 21))])\n",
    "onehot_categorical_features = onehot_encoder.fit_transform(categorical_features).toarray()\n",
    "\n",
    "# RSPS(目标)\n",
    "df_features[\"RSRP\"] = df_raw[\"RSRP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RS Power</th>\n",
       "      <th>log frequency band</th>\n",
       "      <th>log hb</th>\n",
       "      <th>log d</th>\n",
       "      <th>log hb * log d</th>\n",
       "      <th>log delta_hv</th>\n",
       "      <th>cos diff angle 2d</th>\n",
       "      <th>sin diff angle 2d</th>\n",
       "      <th>cos diff angle 3d</th>\n",
       "      <th>sin diff angle 3d</th>\n",
       "      <th>log Cell Building Height</th>\n",
       "      <th>log Building Height</th>\n",
       "      <th>density</th>\n",
       "      <th>RSRP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.2</td>\n",
       "      <td>7.857481</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>6.483235</td>\n",
       "      <td>22.469179</td>\n",
       "      <td>4.271048</td>\n",
       "      <td>0.967311</td>\n",
       "      <td>0.253594</td>\n",
       "      <td>0.500898</td>\n",
       "      <td>0.865506</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>-102.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.2</td>\n",
       "      <td>7.857481</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>6.483235</td>\n",
       "      <td>22.469179</td>\n",
       "      <td>4.271048</td>\n",
       "      <td>0.964513</td>\n",
       "      <td>0.264036</td>\n",
       "      <td>0.500898</td>\n",
       "      <td>0.865506</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>-100.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.2</td>\n",
       "      <td>7.857481</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>4.270943</td>\n",
       "      <td>13.573286</td>\n",
       "      <td>2.538558</td>\n",
       "      <td>0.091065</td>\n",
       "      <td>0.995845</td>\n",
       "      <td>0.517957</td>\n",
       "      <td>0.855407</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>-70.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.2</td>\n",
       "      <td>7.857481</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>4.591228</td>\n",
       "      <td>14.591168</td>\n",
       "      <td>2.125950</td>\n",
       "      <td>-0.008125</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.516830</td>\n",
       "      <td>0.856088</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>-65.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.2</td>\n",
       "      <td>7.857481</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>4.519479</td>\n",
       "      <td>14.363149</td>\n",
       "      <td>2.247309</td>\n",
       "      <td>0.011209</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.517355</td>\n",
       "      <td>0.855771</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>-64.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.2</td>\n",
       "      <td>7.857481</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.696632</td>\n",
       "      <td>11.748094</td>\n",
       "      <td>2.868769</td>\n",
       "      <td>0.388722</td>\n",
       "      <td>0.921355</td>\n",
       "      <td>0.504359</td>\n",
       "      <td>0.863494</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>-75.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.2</td>\n",
       "      <td>7.857481</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>4.658475</td>\n",
       "      <td>14.804884</td>\n",
       "      <td>1.987105</td>\n",
       "      <td>-0.024948</td>\n",
       "      <td>0.999689</td>\n",
       "      <td>0.516244</td>\n",
       "      <td>0.856442</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>-67.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.2</td>\n",
       "      <td>7.857481</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>10.092767</td>\n",
       "      <td>2.946562</td>\n",
       "      <td>0.992820</td>\n",
       "      <td>0.119615</td>\n",
       "      <td>0.469350</td>\n",
       "      <td>0.883012</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>-78.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.2</td>\n",
       "      <td>7.857481</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.293086</td>\n",
       "      <td>10.465604</td>\n",
       "      <td>2.982412</td>\n",
       "      <td>0.785872</td>\n",
       "      <td>0.618389</td>\n",
       "      <td>0.472744</td>\n",
       "      <td>0.881200</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>-72.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.2</td>\n",
       "      <td>7.857481</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>3.414897</td>\n",
       "      <td>10.707389</td>\n",
       "      <td>2.900483</td>\n",
       "      <td>0.936442</td>\n",
       "      <td>-0.350823</td>\n",
       "      <td>0.488251</td>\n",
       "      <td>0.872703</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>-46.051702</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>-75.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RS Power  log frequency band    log hb     log d  log hb * log d  \\\n",
       "0      16.2            7.857481  3.465736  6.483235       22.469179   \n",
       "1      16.2            7.857481  3.465736  6.483235       22.469179   \n",
       "2      16.2            7.857481  3.178054  4.270943       13.573286   \n",
       "3      16.2            7.857481  3.178054  4.591228       14.591168   \n",
       "4      16.2            7.857481  3.178054  4.519479       14.363149   \n",
       "5      16.2            7.857481  3.178054  3.696632       11.748094   \n",
       "6      16.2            7.857481  3.178054  4.658475       14.804884   \n",
       "7      16.2            7.857481  3.135494  3.218876       10.092767   \n",
       "8      16.2            7.857481  3.178054  3.293086       10.465604   \n",
       "9      16.2            7.857481  3.135494  3.414897       10.707389   \n",
       "\n",
       "   log delta_hv  cos diff angle 2d  sin diff angle 2d  cos diff angle 3d  \\\n",
       "0      4.271048           0.967311           0.253594           0.500898   \n",
       "1      4.271048           0.964513           0.264036           0.500898   \n",
       "2      2.538558           0.091065           0.995845           0.517957   \n",
       "3      2.125950          -0.008125           0.999967           0.516830   \n",
       "4      2.247309           0.011209           0.999937           0.517355   \n",
       "5      2.868769           0.388722           0.921355           0.504359   \n",
       "6      1.987105          -0.024948           0.999689           0.516244   \n",
       "7      2.946562           0.992820           0.119615           0.469350   \n",
       "8      2.982412           0.785872           0.618389           0.472744   \n",
       "9      2.900483           0.936442          -0.350823           0.488251   \n",
       "\n",
       "   sin diff angle 3d  log Cell Building Height  log Building Height   density  \\\n",
       "0           0.865506                -46.051702           -46.051702  0.000747   \n",
       "1           0.865506                -46.051702           -46.051702  0.000747   \n",
       "2           0.855407                -46.051702           -46.051702  0.000747   \n",
       "3           0.856088                -46.051702           -46.051702  0.000747   \n",
       "4           0.855771                -46.051702           -46.051702  0.000747   \n",
       "5           0.863494                -46.051702           -46.051702  0.000747   \n",
       "6           0.856442                -46.051702           -46.051702  0.000747   \n",
       "7           0.883012                -46.051702           -46.051702  0.000747   \n",
       "8           0.881200                -46.051702           -46.051702  0.000747   \n",
       "9           0.872703                -46.051702           -46.051702  0.000747   \n",
       "\n",
       "     RSRP  \n",
       "0 -102.20  \n",
       "1 -100.75  \n",
       "2  -70.20  \n",
       "3  -65.25  \n",
       "4  -64.20  \n",
       "5  -75.33  \n",
       "6  -67.44  \n",
       "7  -78.57  \n",
       "8  -72.63  \n",
       "9  -75.25  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5957548, 14)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_features)[:, :-1]\n",
    "continous_feature_len = X.shape[1]\n",
    "X = np.concatenate([X, onehot_categorical_features], axis=1)\n",
    "y = np.array(df_features)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=40, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_scaled = X_train\n",
    "X_test_scaled = X_test\n",
    "X_train_scaled[:, :continous_feature_len] = scaler.fit_transform(X_train[:, :continous_feature_len])\n",
    "X_test_scaled[:, :continous_feature_len] = scaler.transform(X_test[:, :continous_feature_len])\n",
    "# model = linear_model.LinearRegression()\n",
    "model = DecisionTreeRegressor(max_depth=40)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25375642e+01,  7.85780485e+00,  2.15749835e+00,  5.48716963e+00,\n",
       "        1.20915046e+01,  2.78705480e+00,  2.20500199e-02,  2.54606415e-02,\n",
       "        2.28527298e-01,  6.68035068e-01, -3.13760914e+01, -3.89782232e+01,\n",
       "        1.00143029e-03])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "y_test_binary = copy.copy(y_test)\n",
    "y_test_pred_binary = copy.copy(y_test_pred)\n",
    "y_test_binary[y_test>=-103] = 0\n",
    "y_test_binary[y_test<-103] = 1\n",
    "y_test_pred_binary[y_test_pred>=-103] = 0\n",
    "y_test_pred_binary[y_test_pred<-103] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error: 44.285528462894824\n",
      "precision : 0.6180445874243957\n",
      "recall : 0.6123464446551743\n",
      "f1 score: 0.6151823215226876\n"
     ]
    }
   ],
   "source": [
    "print (\"mean squared error: {}\".format(mean_squared_error(y_test, y_test_pred)))\n",
    "print (\"precision : {}\".format(precision_score(y_test_binary, y_test_pred_binary)))\n",
    "print (\"recall : {}\".format(recall_score(y_test_binary, y_test_pred_binary)))\n",
    "print (\"f1 score: {}\".format(f1_score(y_test_binary, y_test_pred_binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = copy.copy(y_train)\n",
    "y_train_binary[y_train>=-103] = 0\n",
    "y_train_binary[y_train<-103] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature_len = X_test_scaled.shape[1]\n",
    "# num_hidden_units_layer_1 = 64\n",
    "# num_hidden_units_layer_2 = 64\n",
    "\n",
    "# X = tf.placeholder(\"float\", [None, feature_len])\n",
    "# y = tf.placeholder(\"float\", [None, 1])\n",
    "# y_binary = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "# W1 = tf.Variable(tf.random_normal([feature_len, num_hidden_units_layer_1]))\n",
    "# b1 = tf.Variable(tf.zeros([1, num_hidden_units_layer_1]) + 0.1)\n",
    "# Z1 = tf.matmul(X, W1) + b1\n",
    "# A1 = tf.nn.relu(Z1)\n",
    "\n",
    "# W2 = tf.Variable(tf.random_normal([num_hidden_units_layer_1, num_hidden_units_layer_2]))\n",
    "# b2 = tf.Variable(tf.zeros([1, num_hidden_units_layer_2]) + 0.1)\n",
    "# Z2 = tf.matmul(A1, W2) + b2\n",
    "# A2 = tf.nn.relu(Z2)\n",
    "# A2 = tf.nn.sigmoid(Z2)\n",
    "\n",
    "# W3 = tf.Variable(tf.random_normal([num_hidden_units_layer_2, 1]))\n",
    "# b3 = tf.Variable(tf.zeros([1, 1]) + 0.1)\n",
    "# Z3 = tf.matmul(A2, W3) + b3\n",
    "# A3 = Z3\n",
    "\n",
    "# mse_loss = tf.reduce_mean((A3 - y) ** 2)\n",
    "# op1 = tf.train.AdamOptimizer().minimize(mse_loss)\n",
    "\n",
    "\n",
    "# threshold = tf.constant(-103.0)\n",
    "# output_prob = tf.nn.sigmoid(threshold - A3)\n",
    "# cross_entropy = -tf.reduce_mean(y_binary * tf.log(tf.clip_by_value(output_prob, 1e-10, 1.0)))\n",
    "# op2 = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "\n",
    "\n",
    "# n_epoch = 3000\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#     for i in range(n_epoch):\n",
    "#         _, train_mse_loss = sess.run([op1, mse_loss], feed_dict={X: X_train_scaled, y: y_train.reshape(-1, 1)})#, y_binary: y_train_binary.reshape(-1, 1)})\n",
    "#         test_mse_loss, y_test_pred = sess.run([mse_loss, A3], feed_dict={X: X_test_scaled, y: y_test.reshape(-1, 1)})#, y_binary: y_test_binary.reshape(-1, 1)})\n",
    "\n",
    "#         _, train_cross_entropy_loss = sess.run([op2, cross_entropy], feed_dict={X: X_train_scaled, y: y_train.reshape(-1, 1), y_binary: y_train_binary.reshape(-1, 1)})\n",
    "#         test_cross_entropy_loss = sess.run(cross_entropy, feed_dict={X: X_test_scaled, y: y_test.reshape(-1, 1), y_binary: y_test_binary.reshape(-1, 1)})\n",
    "        \n",
    "#         y_test_pred_binary = copy.copy(y_test_pred)\n",
    "#         y_test_pred_binary[y_test_pred>=-103] = 0\n",
    "#         y_test_pred_binary[y_test_pred<-103] = 1\n",
    "#         test_f1_score = f1_score(y_test_binary, y_test_pred_binary)\n",
    "        \n",
    "#         print (\"train mse loss: {}, test mse loss: {}, test f1 score: {}\".format(train_mse_loss, test_mse_loss, test_f1_score))\n",
    "        \n",
    "#         print (\"train cross entropy loss: {}, test cross entropy loss: {}\".format(train_cross_entropy_loss, test_cross_entropy_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.python.framework import graph_util\n",
    "# pb_file_path = os.getcwd()\n",
    "# with tf.Session(graph=tf.Graph()) as sess:\n",
    "    \n",
    "#     feature_len = X_test_scaled.shape[1]\n",
    "#     num_hidden_units_layer_1 = 64\n",
    "#     num_hidden_units_layer_2 = 64\n",
    "\n",
    "#     X = tf.placeholder(\"float\", [None, feature_len])\n",
    "#     y = tf.placeholder(\"float\", [None, 1])\n",
    "#     y_binary = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "#     W1 = tf.Variable(tf.random_normal([feature_len, num_hidden_units_layer_1]))\n",
    "#     b1 = tf.Variable(tf.zeros([1, num_hidden_units_layer_1]) + 0.1)\n",
    "#     Z1 = tf.matmul(X, W1) + b1\n",
    "#     A1 = tf.nn.relu(Z1)\n",
    "\n",
    "#     W2 = tf.Variable(tf.random_normal([num_hidden_units_layer_1, num_hidden_units_layer_2]))\n",
    "#     b2 = tf.Variable(tf.zeros([1, num_hidden_units_layer_2]) + 0.1)\n",
    "#     Z2 = tf.matmul(A1, W2) + b2\n",
    "#     A2 = tf.nn.sigmoid(Z2)\n",
    "\n",
    "#     W3 = tf.Variable(tf.random_normal([num_hidden_units_layer_2, 1]))\n",
    "#     b3 = tf.Variable(tf.zeros([1, 1]) + 0.1)\n",
    "#     Z3 = tf.add(tf.matmul(A2, W3), b3, name=\"output\")\n",
    "#     A3 = Z3\n",
    "\n",
    "#     mse_loss = tf.reduce_mean((A3 - y) ** 2)\n",
    "#     op1 = tf.train.AdadeltaOptimizer(learning_rate=30).minimize(mse_loss)\n",
    "\n",
    "\n",
    "#     threshold = tf.constant(-103.0)\n",
    "#     output_prob = tf.nn.sigmoid(threshold - A3)\n",
    "#     cross_entropy = -tf.reduce_mean(y_binary * tf.log(tf.clip_by_value(output_prob, 1e-10, 1.0)))\n",
    "#     op2 = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "    \n",
    "    \n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     n_epoch = 10\n",
    "#     constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, ['output'])\n",
    "    \n",
    "#     for i in range(n_epoch):\n",
    "#         _, train_mse_loss = sess.run([op1, mse_loss], feed_dict={X: X_train_scaled, y: y_train.reshape(-1, 1), y_binary: y_train_binary.reshape(-1, 1)})\n",
    "#         test_mse_loss, y_test_pred = sess.run([mse_loss, A3], feed_dict={X: X_test_scaled, y: y_test.reshape(-1, 1), y_binary: y_test_binary.reshape(-1, 1)})\n",
    "\n",
    "#         y_test_pred_binary = copy.copy(y_test_pred)\n",
    "#         y_test_pred_binary[y_test_pred>=-103] = 0\n",
    "#         y_test_pred_binary[y_test_pred<-103] = 1\n",
    "#         test_f1_score = f1_score(y_test_binary, y_test_pred_binary)\n",
    "        \n",
    "#         print (\"train mse loss: {}, test mse loss: {}, test f1 score: {}\".format(train_mse_loss, test_mse_loss, test_f1_score))\n",
    "    \n",
    "    \n",
    "#     for i in range(n_epoch):\n",
    "#         _, train_cross_entropy_loss = sess.run([op2, cross_entropy], feed_dict={X: X_train_scaled, y: y_train.reshape(-1, 1), y_binary: y_train_binary.reshape(-1, 1)})\n",
    "#         test_mse_loss, test_cross_entropy_loss, y_test_pred = sess.run([mse_loss, cross_entropy, A3], feed_dict={X: X_test_scaled, y: y_test.reshape(-1, 1), y_binary: y_test_binary.reshape(-1, 1)})\n",
    "        \n",
    "#         y_test_pred_binary = copy.copy(y_test_pred)\n",
    "#         y_test_pred_binary[y_test_pred>=-103] = 0\n",
    "#         y_test_pred_binary[y_test_pred<-103] = 1\n",
    "#         test_f1_score = f1_score(y_test_binary, y_test_pred_binary)\n",
    "        \n",
    "#         print (\"test mse loss: {}, test cross entropy loss: {}, test f1 score: {}\".format(test_mse_loss, test_cross_entropy_loss, test_f1_score))\n",
    "        \n",
    "#     with tf.gfile.FastGFile(pb_file_path+'/model.pb', mode='wb') as f:\n",
    "#         f.write(constant_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss: 9578.6806640625, test mse loss: 7346.40673828125, test f1 score: 0.2262572243359135\n",
      "train mse loss: 7328.66259765625, test mse loss: 5737.25634765625, test f1 score: 0.22816616176979201\n",
      "train mse loss: 5722.0029296875, test mse loss: 4559.77392578125, test f1 score: 0.22337617841828297\n",
      "train mse loss: 4547.71240234375, test mse loss: 3709.083984375, test f1 score: 0.22596486303292548\n",
      "train mse loss: 3698.158935546875, test mse loss: 3081.96240234375, test f1 score: 0.2197266779968803\n",
      "train mse loss: 3072.845703125, test mse loss: 2620.433837890625, test f1 score: 0.2241894549921296\n",
      "train mse loss: 2611.704833984375, test mse loss: 2274.58203125, test f1 score: 0.21574032414293098\n",
      "train mse loss: 2267.00390625, test mse loss: 2016.0076904296875, test f1 score: 0.22313885203019457\n",
      "train mse loss: 2008.33203125, test mse loss: 1819.9495849609375, test f1 score: 0.2101744845962082\n",
      "train mse loss: 1813.2119140625, test mse loss: 1671.728515625, test f1 score: 0.22175651054007298\n",
      "train mse loss: 1664.652099609375, test mse loss: 1558.537841796875, test f1 score: 0.20347782931531427\n",
      "train mse loss: 1552.404541015625, test mse loss: 1471.884521484375, test f1 score: 0.22165470399523657\n",
      "train mse loss: 1465.26416015625, test mse loss: 1405.02490234375, test f1 score: 0.19585584039316697\n",
      "train mse loss: 1399.3798828125, test mse loss: 1351.85986328125, test f1 score: 0.22233862756370737\n",
      "train mse loss: 1345.615966796875, test mse loss: 1309.772216796875, test f1 score: 0.1900366309832221\n",
      "train mse loss: 1304.5584716796875, test mse loss: 1273.3553466796875, test f1 score: 0.2230084898111164\n",
      "train mse loss: 1267.4886474609375, test mse loss: 1242.9129638671875, test f1 score: 0.1832869096053252\n",
      "train mse loss: 1238.0867919921875, test mse loss: 1213.8807373046875, test f1 score: 0.22416568591642658\n",
      "train mse loss: 1208.3990478515625, test mse loss: 1188.416015625, test f1 score: 0.17756889651887486\n",
      "train mse loss: 1183.91845703125, test mse loss: 1161.8701171875, test f1 score: 0.22486261496383186\n",
      "train mse loss: 1156.7452392578125, test mse loss: 1137.737548828125, test f1 score: 0.17370443464474772\n",
      "train mse loss: 1133.5244140625, test mse loss: 1111.641845703125, test f1 score: 0.22527597099974306\n",
      "train mse loss: 1106.852294921875, test mse loss: 1087.9368896484375, test f1 score: 0.17188510743968877\n",
      "train mse loss: 1083.9736328125, test mse loss: 1061.798095703125, test f1 score: 0.22584241281174747\n",
      "train mse loss: 1057.3170166015625, test mse loss: 1038.255615234375, test f1 score: 0.1709656549745436\n",
      "train mse loss: 1034.5123291015625, test mse loss: 1012.3824462890625, test f1 score: 0.22602919532481874\n",
      "train mse loss: 1008.1915283203125, test mse loss: 989.0028076171875, test f1 score: 0.17063253846945808\n",
      "train mse loss: 985.4530639648438, test mse loss: 964.00048828125, test f1 score: 0.226036870886967\n",
      "train mse loss: 960.09619140625, test mse loss: 941.4533081054688, test f1 score: 0.17048398516224203\n",
      "train mse loss: 938.0953979492188, test mse loss: 917.8004150390625, test f1 score: 0.22611160484102902\n",
      "train mse loss: 914.1511840820312, test mse loss: 896.520263671875, test f1 score: 0.1709911045647797\n",
      "train mse loss: 893.35009765625, test mse loss: 874.4755249023438, test f1 score: 0.22604000426507065\n",
      "train mse loss: 871.0624389648438, test mse loss: 854.6202392578125, test f1 score: 0.17140930589700407\n",
      "train mse loss: 851.6246948242188, test mse loss: 834.3613891601562, test f1 score: 0.22587206471999222\n",
      "train mse loss: 831.1755981445312, test mse loss: 816.1657104492188, test f1 score: 0.17193801259685532\n",
      "train mse loss: 813.324462890625, test mse loss: 797.7298583984375, test f1 score: 0.22590734106133215\n",
      "train mse loss: 794.7594604492188, test mse loss: 781.3936767578125, test f1 score: 0.17244633856812033\n",
      "train mse loss: 778.693359375, test mse loss: 764.7936401367188, test f1 score: 0.22593523852356676\n",
      "train mse loss: 762.0171508789062, test mse loss: 750.2799682617188, test f1 score: 0.17281815374112064\n",
      "train mse loss: 747.7039184570312, test mse loss: 735.445068359375, test f1 score: 0.2257933558708197\n",
      "train mse loss: 732.8441162109375, test mse loss: 722.6298828125, test f1 score: 0.17354865019166463\n",
      "train mse loss: 720.1826171875, test mse loss: 709.4111328125, test f1 score: 0.22563546482634064\n",
      "train mse loss: 706.9697875976562, test mse loss: 698.1851196289062, test f1 score: 0.1736910411368344\n",
      "train mse loss: 695.8533935546875, test mse loss: 686.4427490234375, test f1 score: 0.2254537039542624\n",
      "train mse loss: 684.1448974609375, test mse loss: 676.7294921875, test f1 score: 0.1737221751305283\n",
      "train mse loss: 674.5025634765625, test mse loss: 666.353759765625, test f1 score: 0.22562142928265333\n",
      "train mse loss: 664.1917114257812, test mse loss: 658.08349609375, test f1 score: 0.17324065191766402\n",
      "train mse loss: 655.9539184570312, test mse loss: 648.83740234375, test f1 score: 0.2258682449392483\n",
      "train mse loss: 646.799560546875, test mse loss: 641.8380126953125, test f1 score: 0.1725663494108706\n",
      "train mse loss: 639.7955932617188, test mse loss: 633.5936279296875, test f1 score: 0.22619285267596548\n",
      "train mse loss: 631.6683959960938, test mse loss: 627.645751953125, test f1 score: 0.17165204237032314\n",
      "train mse loss: 625.6803588867188, test mse loss: 620.2552490234375, test f1 score: 0.226585899600489\n",
      "train mse loss: 618.441162109375, test mse loss: 615.18359375, test f1 score: 0.17063973179452444\n",
      "train mse loss: 613.2867431640625, test mse loss: 608.541748046875, test f1 score: 0.22719941848579153\n",
      "train mse loss: 606.835205078125, test mse loss: 604.227294921875, test f1 score: 0.16948640535834264\n",
      "train mse loss: 602.38818359375, test mse loss: 598.1578369140625, test f1 score: 0.22781621164973131\n",
      "train mse loss: 596.548828125, test mse loss: 594.5847778320312, test f1 score: 0.16840604706006582\n",
      "train mse loss: 592.8030395507812, test mse loss: 588.9974975585938, test f1 score: 0.22817399504892136\n",
      "train mse loss: 587.4785766601562, test mse loss: 586.1016235351562, test f1 score: 0.1670794793745219\n",
      "train mse loss: 584.3756713867188, test mse loss: 580.9537353515625, test f1 score: 0.22857304015116617\n",
      "train mse loss: 579.5198974609375, test mse loss: 578.5953979492188, test f1 score: 0.16559993489288977\n",
      "train mse loss: 576.922607421875, test mse loss: 573.7935791015625, test f1 score: 0.22902787792521562\n",
      "train mse loss: 572.442138671875, test mse loss: 571.8767700195312, test f1 score: 0.16373665898380727\n",
      "train mse loss: 570.253662109375, test mse loss: 567.3497314453125, test f1 score: 0.2295853662175671\n",
      "train mse loss: 566.0750732421875, test mse loss: 565.7780151367188, test f1 score: 0.16220052114861302\n",
      "train mse loss: 564.2022094726562, test mse loss: 561.400390625, test f1 score: 0.2301843521213725\n",
      "train mse loss: 560.1954956054688, test mse loss: 560.0472412109375, test f1 score: 0.16057130327614752\n",
      "train mse loss: 558.515625, test mse loss: 555.7364501953125, test f1 score: 0.23073843214818388\n",
      "train mse loss: 554.5971069335938, test mse loss: 554.4785766601562, test f1 score: 0.15882372103807807\n",
      "train mse loss: 552.9856567382812, test mse loss: 550.1668701171875, test f1 score: 0.23153254104979562\n",
      "train mse loss: 549.0881958007812, test mse loss: 548.8997192382812, test f1 score: 0.15690287205455192\n",
      "train mse loss: 547.4404296875, test mse loss: 544.5016479492188, test f1 score: 0.23221238288720025\n",
      "train mse loss: 543.47998046875, test mse loss: 543.2345581054688, test f1 score: 0.1551608638339754\n",
      "train mse loss: 541.8067626953125, test mse loss: 538.70166015625, test f1 score: 0.23287384308061826\n",
      "train mse loss: 537.7323608398438, test mse loss: 537.365966796875, test f1 score: 0.15357994965959637\n",
      "train mse loss: 535.9682006835938, test mse loss: 532.6791381835938, test f1 score: 0.2334353473572952\n",
      "train mse loss: 531.7576293945312, test mse loss: 531.2354125976562, test f1 score: 0.15192490260580896\n",
      "train mse loss: 529.8682861328125, test mse loss: 526.3545532226562, test f1 score: 0.23411281611893228\n",
      "train mse loss: 525.4747314453125, test mse loss: 524.7835083007812, test f1 score: 0.15045083378923269\n",
      "train mse loss: 523.4459228515625, test mse loss: 519.7517700195312, test f1 score: 0.23467010676513217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss: 518.9132080078125, test mse loss: 518.0658569335938, test f1 score: 0.14923956899707363\n",
      "train mse loss: 516.7548217773438, test mse loss: 512.9744873046875, test f1 score: 0.23521813549332699\n",
      "train mse loss: 512.175537109375, test mse loss: 511.2935485839844, test f1 score: 0.14823089098463363\n",
      "train mse loss: 510.01043701171875, test mse loss: 506.1645812988281, test f1 score: 0.23562657818211652\n",
      "train mse loss: 505.4034118652344, test mse loss: 504.5299072265625, test f1 score: 0.1475151573017616\n",
      "train mse loss: 503.27398681640625, test mse loss: 499.4068603515625, test f1 score: 0.23596873363178617\n",
      "train mse loss: 498.67919921875, test mse loss: 497.83392333984375, test f1 score: 0.14647696420279369\n",
      "train mse loss: 496.6057434082031, test mse loss: 492.76348876953125, test f1 score: 0.23641830426031685\n",
      "train mse loss: 492.0677185058594, test mse loss: 491.2736511230469, test f1 score: 0.14546366147098416\n",
      "train mse loss: 490.0742492675781, test mse loss: 486.2801818847656, test f1 score: 0.23681297671516838\n",
      "train mse loss: 485.6159362792969, test mse loss: 484.8908386230469, test f1 score: 0.14469264627036785\n",
      "train mse loss: 483.720703125, test mse loss: 479.9942626953125, test f1 score: 0.23726922770449055\n",
      "train mse loss: 479.35833740234375, test mse loss: 478.719970703125, test f1 score: 0.1437969583874802\n",
      "train mse loss: 477.5771789550781, test mse loss: 473.91339111328125, test f1 score: 0.23767750761745735\n",
      "train mse loss: 473.303955078125, test mse loss: 472.7322692871094, test f1 score: 0.1430936912751678\n",
      "train mse loss: 471.6145935058594, test mse loss: 468.011474609375, test f1 score: 0.23809060341677243\n",
      "train mse loss: 467.4254455566406, test mse loss: 466.92156982421875, test f1 score: 0.14233603457590494\n",
      "train mse loss: 465.8269958496094, test mse loss: 462.2742614746094, test f1 score: 0.23837342939470668\n",
      "train mse loss: 461.7107238769531, test mse loss: 461.28167724609375, test f1 score: 0.14160820526207024\n",
      "train mse loss: 460.2075500488281, test mse loss: 456.723876953125, test f1 score: 0.23873284622614674\n",
      "train mse loss: 456.18060302734375, test mse loss: 455.8105773925781, test f1 score: 0.14115561003907492\n",
      "train mse loss: 454.7569580078125, test mse loss: 451.3307800292969, test f1 score: 0.23909274496448196\n",
      "train mse loss: 450.803955078125, test mse loss: 450.5160217285156, test f1 score: 0.14024254524859456\n",
      "train mse loss: 449.48443603515625, test mse loss: 446.10638427734375, test f1 score: 0.23956831743840296\n",
      "train mse loss: 445.59503173828125, test mse loss: 445.3673400878906, test f1 score: 0.13932536397991316\n",
      "train mse loss: 444.3577575683594, test mse loss: 441.0525817871094, test f1 score: 0.2398489925909911\n",
      "train mse loss: 440.55322265625, test mse loss: 440.42962646484375, test f1 score: 0.1380818857174775\n",
      "train mse loss: 439.4420471191406, test mse loss: 436.2089538574219, test f1 score: 0.24021629141253537\n",
      "train mse loss: 435.7181701660156, test mse loss: 435.6691589355469, test f1 score: 0.13719244214146817\n",
      "train mse loss: 434.7013854980469, test mse loss: 431.5312194824219, test f1 score: 0.2405451631035182\n",
      "train mse loss: 431.0485534667969, test mse loss: 431.1031188964844, test f1 score: 0.13624212378492562\n",
      "train mse loss: 430.15350341796875, test mse loss: 427.0456848144531, test f1 score: 0.240931333698555\n",
      "train mse loss: 426.5719299316406, test mse loss: 426.7427673339844, test f1 score: 0.13511858557760814\n",
      "train mse loss: 425.80987548828125, test mse loss: 422.7601623535156, test f1 score: 0.24127355886247495\n",
      "train mse loss: 422.29559326171875, test mse loss: 422.58746337890625, test f1 score: 0.13431533130977608\n",
      "train mse loss: 421.6683349609375, test mse loss: 418.6564636230469, test f1 score: 0.2415933724029683\n",
      "train mse loss: 418.2005310058594, test mse loss: 418.5732727050781, test f1 score: 0.13364440950472953\n",
      "train mse loss: 417.6661376953125, test mse loss: 414.6844482421875, test f1 score: 0.2419283334340191\n",
      "train mse loss: 414.23773193359375, test mse loss: 414.6533508300781, test f1 score: 0.13280826016169656\n",
      "train mse loss: 413.75750732421875, test mse loss: 410.7942199707031, test f1 score: 0.24226073063055276\n",
      "train mse loss: 410.3555603027344, test mse loss: 410.7875671386719, test f1 score: 0.13194624325882157\n",
      "train mse loss: 409.9021301269531, test mse loss: 406.9371032714844, test f1 score: 0.24267970947844267\n",
      "train mse loss: 406.5076599121094, test mse loss: 406.86627197265625, test f1 score: 0.13115223622709016\n",
      "train mse loss: 405.9925231933594, test mse loss: 403.0076599121094, test f1 score: 0.24308564184780582\n",
      "train mse loss: 402.58624267578125, test mse loss: 402.9239807128906, test f1 score: 0.13014238825001773\n",
      "train mse loss: 402.06329345703125, test mse loss: 399.0545654296875, test f1 score: 0.24357587371757833\n",
      "train mse loss: 398.6401062011719, test mse loss: 398.98797607421875, test f1 score: 0.12920289270129487\n",
      "train mse loss: 398.1407775878906, test mse loss: 395.1064147949219, test f1 score: 0.243965958846998\n",
      "train mse loss: 394.69964599609375, test mse loss: 395.07733154296875, test f1 score: 0.12831263915769175\n",
      "train mse loss: 394.2445983886719, test mse loss: 391.17620849609375, test f1 score: 0.2441860029519521\n",
      "train mse loss: 390.77886962890625, test mse loss: 391.18603515625, test f1 score: 0.12754616135664132\n",
      "train mse loss: 390.3666076660156, test mse loss: 387.2933044433594, test f1 score: 0.24447175369143886\n",
      "train mse loss: 386.9045715332031, test mse loss: 387.3431396484375, test f1 score: 0.1265393108901725\n",
      "train mse loss: 386.5357971191406, test mse loss: 383.4840393066406, test f1 score: 0.24483987638261237\n",
      "train mse loss: 383.1023254394531, test mse loss: 383.5783996582031, test f1 score: 0.12523904049327778\n",
      "train mse loss: 382.78179931640625, test mse loss: 379.7682189941406, test f1 score: 0.24515763241518437\n",
      "train mse loss: 379.3927001953125, test mse loss: 379.8966369628906, test f1 score: 0.12437277731767916\n",
      "train mse loss: 379.11090087890625, test mse loss: 376.14898681640625, test f1 score: 0.2455849644862705\n",
      "train mse loss: 375.78045654296875, test mse loss: 376.3372802734375, test f1 score: 0.12381929129329061\n",
      "train mse loss: 375.5616455078125, test mse loss: 372.6601867675781, test f1 score: 0.2458768715278172\n",
      "train mse loss: 372.29962158203125, test mse loss: 372.9119873046875, test f1 score: 0.12327715963757638\n",
      "train mse loss: 372.14654541015625, test mse loss: 369.2978515625, test f1 score: 0.24623010405035936\n",
      "train mse loss: 368.9458923339844, test mse loss: 369.5902099609375, test f1 score: 0.12243636804077586\n",
      "train mse loss: 368.83538818359375, test mse loss: 366.0374755859375, test f1 score: 0.24652804128405556\n",
      "train mse loss: 365.6946105957031, test mse loss: 366.3930969238281, test f1 score: 0.1214875930366928\n",
      "train mse loss: 365.6485290527344, test mse loss: 362.8962707519531, test f1 score: 0.24680323063958193\n",
      "train mse loss: 362.56109619140625, test mse loss: 363.3035583496094, test f1 score: 0.12060429541332988\n",
      "train mse loss: 362.5692138671875, test mse loss: 359.8595886230469, test f1 score: 0.24706318995051388\n",
      "train mse loss: 359.5302734375, test mse loss: 360.3118896484375, test f1 score: 0.11965837698962284\n",
      "train mse loss: 359.5880432128906, test mse loss: 356.91107177734375, test f1 score: 0.24744022425788897\n",
      "train mse loss: 356.58697509765625, test mse loss: 357.38720703125, test f1 score: 0.11850682907891884\n",
      "train mse loss: 356.67352294921875, test mse loss: 354.01953125, test f1 score: 0.24770410232189796\n",
      "train mse loss: 353.700439453125, test mse loss: 354.5437316894531, test f1 score: 0.11762828954032536\n",
      "train mse loss: 353.83990478515625, test mse loss: 351.21875, test f1 score: 0.24796651254871718\n",
      "train mse loss: 350.9044494628906, test mse loss: 351.7793273925781, test f1 score: 0.11675643753881869\n",
      "train mse loss: 351.0845642089844, test mse loss: 348.4920959472656, test f1 score: 0.24821306075354255\n",
      "train mse loss: 348.181396484375, test mse loss: 349.0808410644531, test f1 score: 0.11571224958226395\n",
      "train mse loss: 348.3941345214844, test mse loss: 345.82757568359375, test f1 score: 0.24848045353133497\n",
      "train mse loss: 345.5199279785156, test mse loss: 346.45428466796875, test f1 score: 0.1147482809872302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss: 345.77471923828125, test mse loss: 343.2320556640625, test f1 score: 0.24871999002465067\n",
      "train mse loss: 342.9267578125, test mse loss: 343.8949279785156, test f1 score: 0.1136531632352409\n",
      "train mse loss: 343.2218933105469, test mse loss: 340.69140625, test f1 score: 0.24889985036812518\n",
      "train mse loss: 340.38885498046875, test mse loss: 341.4009704589844, test f1 score: 0.11297035281166674\n",
      "train mse loss: 340.7342224121094, test mse loss: 338.2217102050781, test f1 score: 0.24911728053170867\n",
      "train mse loss: 337.92205810546875, test mse loss: 338.95928955078125, test f1 score: 0.11225762025739071\n",
      "train mse loss: 338.3000183105469, test mse loss: 335.7852783203125, test f1 score: 0.24949170555889283\n",
      "train mse loss: 335.48736572265625, test mse loss: 336.54315185546875, test f1 score: 0.11164219154533922\n",
      "train mse loss: 335.8908386230469, test mse loss: 333.3974304199219, test f1 score: 0.24977391968315976\n",
      "train mse loss: 333.1014099121094, test mse loss: 334.145263671875, test f1 score: 0.1108578227496236\n",
      "train mse loss: 333.50006103515625, test mse loss: 331.0255432128906, test f1 score: 0.2501529961176632\n",
      "train mse loss: 330.7310485839844, test mse loss: 331.7890625, test f1 score: 0.10980736385124239\n",
      "train mse loss: 331.1517333984375, test mse loss: 328.6958312988281, test f1 score: 0.2505153124166122\n",
      "train mse loss: 328.40216064453125, test mse loss: 329.4827880859375, test f1 score: 0.10901635643701085\n",
      "train mse loss: 328.8528747558594, test mse loss: 326.4158935546875, test f1 score: 0.25085995490380025\n",
      "train mse loss: 326.1224670410156, test mse loss: 327.2191467285156, test f1 score: 0.10819489376001794\n",
      "train mse loss: 326.59503173828125, test mse loss: 324.17413330078125, test f1 score: 0.2511637467555196\n",
      "train mse loss: 323.88116455078125, test mse loss: 324.9915466308594, test f1 score: 0.10747763672398093\n",
      "train mse loss: 324.3733215332031, test mse loss: 321.9489440917969, test f1 score: 0.25146707575198557\n",
      "train mse loss: 321.6567687988281, test mse loss: 322.776123046875, test f1 score: 0.10657177362306912\n",
      "train mse loss: 322.1623229980469, test mse loss: 319.7499694824219, test f1 score: 0.2517508221717002\n",
      "train mse loss: 319.4595031738281, test mse loss: 320.5912170410156, test f1 score: 0.10567834841134212\n",
      "train mse loss: 319.98162841796875, test mse loss: 317.5642395019531, test f1 score: 0.25191867169482013\n",
      "train mse loss: 317.2761535644531, test mse loss: 318.4211730957031, test f1 score: 0.10509167398540588\n",
      "train mse loss: 317.8166198730469, test mse loss: 315.3938293457031, test f1 score: 0.2521837021775564\n",
      "train mse loss: 315.1085205078125, test mse loss: 316.2677001953125, test f1 score: 0.10437801119190832\n",
      "train mse loss: 315.66925048828125, test mse loss: 313.2421875, test f1 score: 0.2523932715716965\n",
      "train mse loss: 312.9598693847656, test mse loss: 314.12261962890625, test f1 score: 0.10390914772773795\n",
      "train mse loss: 313.5312194824219, test mse loss: 311.1076354980469, test f1 score: 0.2525845169856474\n",
      "train mse loss: 310.82769775390625, test mse loss: 311.9996032714844, test f1 score: 0.10309171071008023\n",
      "train mse loss: 311.41510009765625, test mse loss: 308.99041748046875, test f1 score: 0.25275588620414013\n",
      "train mse loss: 308.7123107910156, test mse loss: 309.88702392578125, test f1 score: 0.10207767006302551\n",
      "train mse loss: 309.3087158203125, test mse loss: 306.8863220214844, test f1 score: 0.2529683882860186\n",
      "train mse loss: 306.6102294921875, test mse loss: 307.7783508300781, test f1 score: 0.10128209371862346\n",
      "train mse loss: 307.2063293457031, test mse loss: 304.7889099121094, test f1 score: 0.253129809173947\n",
      "train mse loss: 304.51409912109375, test mse loss: 305.6692199707031, test f1 score: 0.10042765206560102\n",
      "train mse loss: 305.10418701171875, test mse loss: 302.7037048339844, test f1 score: 0.2533369379893912\n",
      "train mse loss: 302.4303283691406, test mse loss: 303.5921325683594, test f1 score: 0.09951318131704866\n",
      "train mse loss: 303.03448486328125, test mse loss: 300.65106201171875, test f1 score: 0.2535351348358707\n",
      "train mse loss: 300.37908935546875, test mse loss: 301.5636901855469, test f1 score: 0.09886109478621502\n",
      "train mse loss: 301.012939453125, test mse loss: 298.64935302734375, test f1 score: 0.2538435552403021\n",
      "train mse loss: 298.37921142578125, test mse loss: 299.587646484375, test f1 score: 0.09832511489516252\n",
      "train mse loss: 299.0438232421875, test mse loss: 296.69512939453125, test f1 score: 0.25410662073142276\n",
      "train mse loss: 296.4267272949219, test mse loss: 297.63665771484375, test f1 score: 0.09772074583584327\n",
      "train mse loss: 297.10028076171875, test mse loss: 294.7628479003906, test f1 score: 0.2542805919304997\n",
      "train mse loss: 294.4963684082031, test mse loss: 295.7043762207031, test f1 score: 0.09698134736285943\n",
      "train mse loss: 295.17669677734375, test mse loss: 292.82086181640625, test f1 score: 0.25440508981647914\n",
      "train mse loss: 292.5560607910156, test mse loss: 293.7489013671875, test f1 score: 0.09655257922530251\n",
      "train mse loss: 293.2295227050781, test mse loss: 290.8749694824219, test f1 score: 0.2544977541201106\n",
      "train mse loss: 290.6115417480469, test mse loss: 291.798095703125, test f1 score: 0.09594894781168568\n",
      "train mse loss: 291.28765869140625, test mse loss: 288.93359375, test f1 score: 0.25471389220153856\n",
      "train mse loss: 288.6712341308594, test mse loss: 289.8476867675781, test f1 score: 0.09536408832736082\n",
      "train mse loss: 289.3469543457031, test mse loss: 286.99835205078125, test f1 score: 0.2547742955360951\n",
      "train mse loss: 286.73614501953125, test mse loss: 287.90087890625, test f1 score: 0.09478600326495848\n",
      "train mse loss: 287.4093017578125, test mse loss: 285.07965087890625, test f1 score: 0.25485567315297253\n",
      "train mse loss: 284.81683349609375, test mse loss: 285.9787292480469, test f1 score: 0.09410425353275177\n",
      "train mse loss: 285.4953308105469, test mse loss: 283.1939697265625, test f1 score: 0.255022142417609\n",
      "train mse loss: 282.9290771484375, test mse loss: 284.0995178222656, test f1 score: 0.09353815251877381\n",
      "train mse loss: 283.62384033203125, test mse loss: 281.3571472167969, test f1 score: 0.25515936085801294\n",
      "train mse loss: 281.08990478515625, test mse loss: 282.27301025390625, test f1 score: 0.09263539723770182\n",
      "train mse loss: 281.8037414550781, test mse loss: 279.56732177734375, test f1 score: 0.2553094910730841\n",
      "train mse loss: 279.29815673828125, test mse loss: 280.50714111328125, test f1 score: 0.09192644965795878\n",
      "train mse loss: 280.0433654785156, test mse loss: 277.8238525390625, test f1 score: 0.2553917825578373\n",
      "train mse loss: 277.5535583496094, test mse loss: 278.7857360839844, test f1 score: 0.0912295037158731\n",
      "train mse loss: 278.3271789550781, test mse loss: 276.1359558105469, test f1 score: 0.25552809553509565\n",
      "train mse loss: 275.86419677734375, test mse loss: 277.1181945800781, test f1 score: 0.09045379799786517\n",
      "train mse loss: 276.66485595703125, test mse loss: 274.4969787597656, test f1 score: 0.2556134817349038\n",
      "train mse loss: 274.2236022949219, test mse loss: 275.4965515136719, test f1 score: 0.08970116963800225\n",
      "train mse loss: 275.0474853515625, test mse loss: 272.90386962890625, test f1 score: 0.25573131005749183\n",
      "train mse loss: 272.62982177734375, test mse loss: 273.9228515625, test f1 score: 0.089119357213665\n",
      "train mse loss: 273.477783203125, test mse loss: 271.3574523925781, test f1 score: 0.25585605118471005\n",
      "train mse loss: 271.083740234375, test mse loss: 272.386474609375, test f1 score: 0.08840356938419114\n",
      "train mse loss: 271.9458923339844, test mse loss: 269.835205078125, test f1 score: 0.2559905924676232\n",
      "train mse loss: 269.5625, test mse loss: 270.87384033203125, test f1 score: 0.0877396879214473\n",
      "train mse loss: 270.437255859375, test mse loss: 268.34075927734375, test f1 score: 0.2560336901556446\n",
      "train mse loss: 268.0696105957031, test mse loss: 269.39593505859375, test f1 score: 0.08707207233518104\n",
      "train mse loss: 268.963623046875, test mse loss: 266.8598327636719, test f1 score: 0.25616832114747223\n",
      "train mse loss: 266.58978271484375, test mse loss: 267.92425537109375, test f1 score: 0.08641584993149964\n",
      "train mse loss: 267.4965515136719, test mse loss: 265.41082763671875, test f1 score: 0.25621047795727114\n",
      "train mse loss: 265.1412048339844, test mse loss: 266.4867248535156, test f1 score: 0.08555716624899495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss: 266.06353759765625, test mse loss: 263.9873046875, test f1 score: 0.2562516314547572\n",
      "train mse loss: 263.71844482421875, test mse loss: 265.0746765136719, test f1 score: 0.08476296673325703\n",
      "train mse loss: 264.656494140625, test mse loss: 262.5874328613281, test f1 score: 0.25645515037384164\n",
      "train mse loss: 262.3194580078125, test mse loss: 263.67938232421875, test f1 score: 0.0839588168849592\n",
      "train mse loss: 263.266357421875, test mse loss: 261.1969299316406, test f1 score: 0.2565397873728015\n",
      "train mse loss: 260.929443359375, test mse loss: 262.2864074707031, test f1 score: 0.08309875813128327\n",
      "train mse loss: 261.87841796875, test mse loss: 259.81427001953125, test f1 score: 0.2566525002410608\n",
      "train mse loss: 259.5471496582031, test mse loss: 260.895263671875, test f1 score: 0.08233128725255118\n",
      "train mse loss: 260.49127197265625, test mse loss: 258.4295654296875, test f1 score: 0.2567520554474941\n",
      "train mse loss: 258.1634826660156, test mse loss: 259.5072021484375, test f1 score: 0.08163228923395076\n",
      "train mse loss: 259.10650634765625, test mse loss: 257.0587158203125, test f1 score: 0.25685859212130546\n",
      "train mse loss: 256.7937927246094, test mse loss: 258.1384582519531, test f1 score: 0.08078082371302286\n",
      "train mse loss: 257.7409973144531, test mse loss: 255.70799255371094, test f1 score: 0.25694073219605673\n",
      "train mse loss: 255.44424438476562, test mse loss: 256.7843017578125, test f1 score: 0.0798717083455274\n",
      "train mse loss: 256.3899230957031, test mse loss: 254.3807830810547, test f1 score: 0.2570553267886872\n",
      "train mse loss: 254.11827087402344, test mse loss: 255.46463012695312, test f1 score: 0.07910186363296161\n",
      "train mse loss: 255.072509765625, test mse loss: 253.07659912109375, test f1 score: 0.2571834873896859\n",
      "train mse loss: 252.8158416748047, test mse loss: 254.1735382080078, test f1 score: 0.07850562640660165\n",
      "train mse loss: 253.7831268310547, test mse loss: 251.8051300048828, test f1 score: 0.25725599608726574\n",
      "train mse loss: 251.546142578125, test mse loss: 252.91444396972656, test f1 score: 0.07793824850974754\n",
      "train mse loss: 252.5261993408203, test mse loss: 250.5586395263672, test f1 score: 0.25749822182777227\n",
      "train mse loss: 250.301025390625, test mse loss: 251.66375732421875, test f1 score: 0.07709209277092093\n",
      "train mse loss: 251.2771759033203, test mse loss: 249.31304931640625, test f1 score: 0.25772206555202504\n",
      "train mse loss: 249.0574493408203, test mse loss: 250.4183807373047, test f1 score: 0.07652213827133651\n",
      "train mse loss: 250.03379821777344, test mse loss: 248.0814971923828, test f1 score: 0.2580029632999409\n",
      "train mse loss: 247.82711791992188, test mse loss: 249.18910217285156, test f1 score: 0.07578403275642404\n",
      "train mse loss: 248.80642700195312, test mse loss: 246.85372924804688, test f1 score: 0.25831992784772073\n",
      "train mse loss: 246.60107421875, test mse loss: 247.9663543701172, test f1 score: 0.0750827985296437\n",
      "train mse loss: 247.5850830078125, test mse loss: 245.63427734375, test f1 score: 0.2585345901779685\n",
      "train mse loss: 245.38316345214844, test mse loss: 246.75216674804688, test f1 score: 0.0744236648412761\n",
      "train mse loss: 246.37200927734375, test mse loss: 244.421875, test f1 score: 0.2587264123472713\n",
      "train mse loss: 244.17202758789062, test mse loss: 245.5377197265625, test f1 score: 0.07383050950662952\n",
      "train mse loss: 245.1587371826172, test mse loss: 243.20938110351562, test f1 score: 0.25887402899694667\n",
      "train mse loss: 242.9600830078125, test mse loss: 244.3207550048828, test f1 score: 0.07307281657057443\n",
      "train mse loss: 243.94248962402344, test mse loss: 241.9882049560547, test f1 score: 0.2590401792833344\n",
      "train mse loss: 241.73904418945312, test mse loss: 243.09442138671875, test f1 score: 0.07256745894700167\n",
      "train mse loss: 242.71624755859375, test mse loss: 240.76760864257812, test f1 score: 0.25919865690021776\n",
      "train mse loss: 240.51913452148438, test mse loss: 241.8769073486328, test f1 score: 0.07199632578077157\n",
      "train mse loss: 241.4987030029297, test mse loss: 239.55569458007812, test f1 score: 0.25935639648640774\n",
      "train mse loss: 239.30796813964844, test mse loss: 240.67201232910156, test f1 score: 0.07142813322454188\n",
      "train mse loss: 240.29457092285156, test mse loss: 238.35809326171875, test f1 score: 0.25955100054025426\n",
      "train mse loss: 238.11074829101562, test mse loss: 239.47779846191406, test f1 score: 0.07086004388418018\n",
      "train mse loss: 239.10072326660156, test mse loss: 237.1719512939453, test f1 score: 0.25973184736190735\n",
      "train mse loss: 236.92555236816406, test mse loss: 238.29844665527344, test f1 score: 0.07001305547344566\n",
      "train mse loss: 237.92088317871094, test mse loss: 236.00885009765625, test f1 score: 0.26000954313324276\n",
      "train mse loss: 235.7636260986328, test mse loss: 237.1441192626953, test f1 score: 0.06928860898475811\n",
      "train mse loss: 236.7654266357422, test mse loss: 234.87327575683594, test f1 score: 0.26027745410764325\n",
      "train mse loss: 234.6285858154297, test mse loss: 236.00286865234375, test f1 score: 0.06856514337443576\n",
      "train mse loss: 235.62326049804688, test mse loss: 233.74403381347656, test f1 score: 0.2604130017634705\n",
      "train mse loss: 233.49932861328125, test mse loss: 234.8777618408203, test f1 score: 0.06804047154924348\n",
      "train mse loss: 234.49659729003906, test mse loss: 232.62599182128906, test f1 score: 0.26048504948171036\n",
      "train mse loss: 232.38099670410156, test mse loss: 233.75453186035156, test f1 score: 0.067382019476937\n",
      "train mse loss: 233.37152099609375, test mse loss: 231.51719665527344, test f1 score: 0.26057164658103493\n",
      "train mse loss: 231.27157592773438, test mse loss: 232.6421661376953, test f1 score: 0.06664866190471756\n",
      "train mse loss: 232.2570037841797, test mse loss: 230.4178924560547, test f1 score: 0.2606516562967083\n",
      "train mse loss: 230.17178344726562, test mse loss: 231.5419158935547, test f1 score: 0.06616067236506214\n",
      "train mse loss: 231.15476989746094, test mse loss: 229.3343048095703, test f1 score: 0.26092550443616463\n",
      "train mse loss: 229.08790588378906, test mse loss: 230.47007751464844, test f1 score: 0.06562095086215489\n",
      "train mse loss: 230.0816192626953, test mse loss: 228.27511596679688, test f1 score: 0.26112112891771694\n",
      "train mse loss: 228.02877807617188, test mse loss: 229.42477416992188, test f1 score: 0.06485751190260765\n",
      "train mse loss: 229.03457641601562, test mse loss: 227.2356719970703, test f1 score: 0.26123179772161365\n",
      "train mse loss: 226.9896240234375, test mse loss: 228.40025329589844, test f1 score: 0.0642965204236006\n",
      "train mse loss: 228.0090789794922, test mse loss: 226.21383666992188, test f1 score: 0.2613071160925621\n",
      "train mse loss: 225.96836853027344, test mse loss: 227.39891052246094, test f1 score: 0.063499520793791\n",
      "train mse loss: 227.00692749023438, test mse loss: 225.21713256835938, test f1 score: 0.2614662689659562\n",
      "train mse loss: 224.97203063964844, test mse loss: 226.41989135742188, test f1 score: 0.062497646216999964\n",
      "train mse loss: 226.0272674560547, test mse loss: 224.24615478515625, test f1 score: 0.26173891431675766\n",
      "train mse loss: 224.0012969970703, test mse loss: 225.4700927734375, test f1 score: 0.06186526184765971\n",
      "train mse loss: 225.07717895507812, test mse loss: 223.29696655273438, test f1 score: 0.26199803466221305\n",
      "train mse loss: 223.05209350585938, test mse loss: 224.53843688964844, test f1 score: 0.06130311614730878\n",
      "train mse loss: 224.14535522460938, test mse loss: 222.36830139160156, test f1 score: 0.26210287944132743\n",
      "train mse loss: 222.12362670898438, test mse loss: 223.62164306640625, test f1 score: 0.0607462935934254\n",
      "train mse loss: 223.2285614013672, test mse loss: 221.4515838623047, test f1 score: 0.26228181240151494\n",
      "train mse loss: 221.20738220214844, test mse loss: 222.71896362304688, test f1 score: 0.06034131761096611\n",
      "train mse loss: 222.32647705078125, test mse loss: 220.5588836669922, test f1 score: 0.2625168547791124\n",
      "train mse loss: 220.3150634765625, test mse loss: 221.8352508544922, test f1 score: 0.05985858732722463\n",
      "train mse loss: 221.44358825683594, test mse loss: 219.64157104492188, test f1 score: 0.262693379717455\n",
      "train mse loss: 219.3971710205078, test mse loss: 220.9190673828125, test f1 score: 0.059400926180912327\n",
      "train mse loss: 220.5293426513672, test mse loss: 218.72901916503906, test f1 score: 0.2627776838696476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss: 218.4844512939453, test mse loss: 220.01466369628906, test f1 score: 0.05908547775182324\n",
      "train mse loss: 219.62704467773438, test mse loss: 217.83055114746094, test f1 score: 0.26291911500914716\n",
      "train mse loss: 217.585205078125, test mse loss: 219.12570190429688, test f1 score: 0.058820355765721456\n",
      "train mse loss: 218.7398223876953, test mse loss: 216.9486846923828, test f1 score: 0.2630557084497717\n",
      "train mse loss: 216.702880859375, test mse loss: 218.25538635253906, test f1 score: 0.05859267003727584\n",
      "train mse loss: 217.87081909179688, test mse loss: 216.0808868408203, test f1 score: 0.26320311643444816\n",
      "train mse loss: 215.83419799804688, test mse loss: 217.3932342529297, test f1 score: 0.058141237434986594\n",
      "train mse loss: 217.0103759765625, test mse loss: 215.2267608642578, test f1 score: 0.26334510796149463\n",
      "train mse loss: 214.9785919189453, test mse loss: 216.54249572753906, test f1 score: 0.05765993265993266\n",
      "train mse loss: 216.1614532470703, test mse loss: 214.3859405517578, test f1 score: 0.2634762419843444\n",
      "train mse loss: 214.135986328125, test mse loss: 215.70291137695312, test f1 score: 0.05714723750023954\n",
      "train mse loss: 215.32345581054688, test mse loss: 213.55142211914062, test f1 score: 0.26366888784101183\n",
      "train mse loss: 213.2992401123047, test mse loss: 214.87030029296875, test f1 score: 0.05666226258761505\n",
      "train mse loss: 214.4924774169922, test mse loss: 212.70924377441406, test f1 score: 0.2639498093268596\n",
      "train mse loss: 212.45474243164062, test mse loss: 214.02386474609375, test f1 score: 0.05629427513674852\n",
      "train mse loss: 213.64808654785156, test mse loss: 211.85910034179688, test f1 score: 0.26411841333720487\n",
      "train mse loss: 211.60321044921875, test mse loss: 213.1805877685547, test f1 score: 0.05581759241742633\n",
      "train mse loss: 212.80697631835938, test mse loss: 211.01976013183594, test f1 score: 0.2643560522865754\n",
      "train mse loss: 210.7628631591797, test mse loss: 212.34776306152344, test f1 score: 0.05539202311210978\n",
      "train mse loss: 211.97589111328125, test mse loss: 210.20101928710938, test f1 score: 0.26457986639305486\n",
      "train mse loss: 209.9434051513672, test mse loss: 211.54037475585938, test f1 score: 0.05501149018914618\n",
      "train mse loss: 211.1708984375, test mse loss: 209.41293334960938, test f1 score: 0.2647267388211336\n",
      "train mse loss: 209.15411376953125, test mse loss: 210.76058959960938, test f1 score: 0.05472178960781538\n",
      "train mse loss: 210.39364624023438, test mse loss: 208.6429901123047, test f1 score: 0.26485393657493733\n",
      "train mse loss: 208.38255310058594, test mse loss: 210.0009002685547, test f1 score: 0.054185906379797574\n",
      "train mse loss: 209.63638305664062, test mse loss: 207.8917694091797, test f1 score: 0.26498863037662307\n",
      "train mse loss: 207.6303253173828, test mse loss: 209.2472686767578, test f1 score: 0.05377135076885352\n",
      "train mse loss: 208.88551330566406, test mse loss: 207.14793395996094, test f1 score: 0.2652064985554069\n",
      "train mse loss: 206.88546752929688, test mse loss: 208.51727294921875, test f1 score: 0.05326019183490181\n",
      "train mse loss: 208.15846252441406, test mse loss: 206.4261016845703, test f1 score: 0.26555865624560215\n",
      "train mse loss: 206.16250610351562, test mse loss: 207.8022918701172, test f1 score: 0.05270496284578331\n",
      "train mse loss: 207.44630432128906, test mse loss: 205.71917724609375, test f1 score: 0.2657619101637293\n",
      "train mse loss: 205.4544677734375, test mse loss: 207.10769653320312, test f1 score: 0.05225696300543952\n",
      "train mse loss: 206.75474548339844, test mse loss: 205.03208923339844, test f1 score: 0.2659043632804746\n",
      "train mse loss: 204.7664337158203, test mse loss: 206.43260192871094, test f1 score: 0.05184103811841038\n",
      "train mse loss: 206.08192443847656, test mse loss: 204.36436462402344, test f1 score: 0.26597999492233587\n",
      "train mse loss: 204.0980224609375, test mse loss: 205.77951049804688, test f1 score: 0.0513990000877116\n",
      "train mse loss: 205.43121337890625, test mse loss: 203.71697998046875, test f1 score: 0.26604019525843675\n",
      "train mse loss: 203.45062255859375, test mse loss: 205.13230895996094, test f1 score: 0.05085197884203747\n",
      "train mse loss: 204.7863006591797, test mse loss: 203.06890869140625, test f1 score: 0.26615806627396454\n",
      "train mse loss: 202.8024139404297, test mse loss: 204.49856567382812, test f1 score: 0.0503103262905827\n",
      "train mse loss: 204.15509033203125, test mse loss: 202.43368530273438, test f1 score: 0.26638335375124295\n",
      "train mse loss: 202.1671142578125, test mse loss: 203.8829345703125, test f1 score: 0.0496860764120035\n",
      "train mse loss: 203.5425567626953, test mse loss: 201.81808471679688, test f1 score: 0.26657749408885145\n",
      "train mse loss: 201.5513458251953, test mse loss: 203.28135681152344, test f1 score: 0.04904434450661507\n",
      "train mse loss: 202.94491577148438, test mse loss: 201.22079467773438, test f1 score: 0.2667695393516939\n",
      "train mse loss: 200.95440673828125, test mse loss: 202.69857788085938, test f1 score: 0.048595903750912446\n",
      "train mse loss: 202.365966796875, test mse loss: 200.64254760742188, test f1 score: 0.26698729420704337\n",
      "train mse loss: 200.37684631347656, test mse loss: 202.1206817626953, test f1 score: 0.04803781142143542\n",
      "train mse loss: 201.7915802001953, test mse loss: 200.0644989013672, test f1 score: 0.26721695979287446\n",
      "train mse loss: 199.7999267578125, test mse loss: 201.53936767578125, test f1 score: 0.04759076275830836\n",
      "train mse loss: 201.21389770507812, test mse loss: 199.48228454589844, test f1 score: 0.2673993312171082\n",
      "train mse loss: 199.2192840576172, test mse loss: 200.96031188964844, test f1 score: 0.047022324759022086\n",
      "train mse loss: 200.638671875, test mse loss: 198.9039764404297, test f1 score: 0.26743485552265606\n",
      "train mse loss: 198.6420135498047, test mse loss: 200.3892822265625, test f1 score: 0.04651453620393467\n",
      "train mse loss: 200.0714874267578, test mse loss: 198.330322265625, test f1 score: 0.2674987743142856\n",
      "train mse loss: 198.0699920654297, test mse loss: 199.82827758789062, test f1 score: 0.046282418281061104\n",
      "train mse loss: 199.51426696777344, test mse loss: 197.76731872558594, test f1 score: 0.26759344568196397\n",
      "train mse loss: 197.5087127685547, test mse loss: 199.26287841796875, test f1 score: 0.04574402474860575\n",
      "train mse loss: 198.95272827148438, test mse loss: 197.20213317871094, test f1 score: 0.26775861827321523\n",
      "train mse loss: 196.94529724121094, test mse loss: 198.70452880859375, test f1 score: 0.04518926845701868\n",
      "train mse loss: 198.3983917236328, test mse loss: 196.64830017089844, test f1 score: 0.26785329926911666\n",
      "train mse loss: 196.39329528808594, test mse loss: 198.16111755371094, test f1 score: 0.0446422960785027\n",
      "train mse loss: 197.85865783691406, test mse loss: 196.10604858398438, test f1 score: 0.26807901463659217\n",
      "train mse loss: 195.85243225097656, test mse loss: 197.63418579101562, test f1 score: 0.04431907349099613\n",
      "train mse loss: 197.33570861816406, test mse loss: 195.5725860595703, test f1 score: 0.2683410117164266\n",
      "train mse loss: 195.3208465576172, test mse loss: 197.1129608154297, test f1 score: 0.04390855036822463\n",
      "train mse loss: 196.81842041015625, test mse loss: 195.05075073242188, test f1 score: 0.26847279066598373\n",
      "train mse loss: 194.80047607421875, test mse loss: 196.59304809570312, test f1 score: 0.04362480675703471\n",
      "train mse loss: 196.3021240234375, test mse loss: 194.52810668945312, test f1 score: 0.2686972397632201\n",
      "train mse loss: 194.279296875, test mse loss: 196.07301330566406, test f1 score: 0.04317621821224821\n",
      "train mse loss: 195.78599548339844, test mse loss: 194.0032958984375, test f1 score: 0.26886392339446946\n",
      "train mse loss: 193.7556610107422, test mse loss: 195.5525665283203, test f1 score: 0.042745128019331696\n",
      "train mse loss: 195.26988220214844, test mse loss: 193.48036193847656, test f1 score: 0.2691280671634306\n",
      "train mse loss: 193.23374938964844, test mse loss: 195.04417419433594, test f1 score: 0.04233899139646143\n",
      "train mse loss: 194.76573181152344, test mse loss: 192.97216796875, test f1 score: 0.2690801457733185\n",
      "train mse loss: 192.72666931152344, test mse loss: 194.54598999023438, test f1 score: 0.04193489301473649\n",
      "train mse loss: 194.271484375, test mse loss: 192.47402954101562, test f1 score: 0.2692282647174085\n",
      "train mse loss: 192.2298583984375, test mse loss: 194.05992126464844, test f1 score: 0.04155222527399269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss: 193.7888946533203, test mse loss: 191.9904327392578, test f1 score: 0.26932496782878385\n",
      "train mse loss: 191.7479248046875, test mse loss: 193.5877227783203, test f1 score: 0.04110887177502236\n",
      "train mse loss: 193.31996154785156, test mse loss: 191.50975036621094, test f1 score: 0.269426260567337\n",
      "train mse loss: 191.26882934570312, test mse loss: 193.1011962890625, test f1 score: 0.04072130687606254\n",
      "train mse loss: 192.8365936279297, test mse loss: 191.01779174804688, test f1 score: 0.26946344342429046\n",
      "train mse loss: 190.77902221679688, test mse loss: 192.60377502441406, test f1 score: 0.04031427616181879\n",
      "train mse loss: 192.34226989746094, test mse loss: 190.51332092285156, test f1 score: 0.26963024066124924\n",
      "train mse loss: 190.2767333984375, test mse loss: 192.10874938964844, test f1 score: 0.039921950044011875\n",
      "train mse loss: 191.85032653808594, test mse loss: 190.01663208007812, test f1 score: 0.2696670268850267\n",
      "train mse loss: 189.78244018554688, test mse loss: 191.6194610595703, test f1 score: 0.03965929728389436\n",
      "train mse loss: 191.36355590820312, test mse loss: 189.52188110351562, test f1 score: 0.2697067141360054\n",
      "train mse loss: 189.2899627685547, test mse loss: 191.13250732421875, test f1 score: 0.03929316579341067\n",
      "train mse loss: 190.87876892089844, test mse loss: 189.02980041503906, test f1 score: 0.26986264605239196\n",
      "train mse loss: 188.79954528808594, test mse loss: 190.64663696289062, test f1 score: 0.03897198301186819\n",
      "train mse loss: 190.3946990966797, test mse loss: 188.5391387939453, test f1 score: 0.26983826070263006\n",
      "train mse loss: 188.3103790283203, test mse loss: 190.1582794189453, test f1 score: 0.03865795804270988\n",
      "train mse loss: 189.9078826904297, test mse loss: 188.04283142089844, test f1 score: 0.26998680247219264\n",
      "train mse loss: 187.8153839111328, test mse loss: 189.65936279296875, test f1 score: 0.03838523768854697\n",
      "train mse loss: 189.4103240966797, test mse loss: 187.53350830078125, test f1 score: 0.27009166976727944\n",
      "train mse loss: 187.30702209472656, test mse loss: 189.14503479003906, test f1 score: 0.03798230767418932\n",
      "train mse loss: 188.8972930908203, test mse loss: 187.01510620117188, test f1 score: 0.2702947911463725\n",
      "train mse loss: 186.789306640625, test mse loss: 188.617431640625, test f1 score: 0.037655804933233665\n",
      "train mse loss: 188.37094116210938, test mse loss: 186.4879150390625, test f1 score: 0.27051368223557914\n",
      "train mse loss: 186.26263427734375, test mse loss: 188.08523559570312, test f1 score: 0.037275869736602726\n",
      "train mse loss: 187.8397979736328, test mse loss: 185.95774841308594, test f1 score: 0.270564406713959\n",
      "train mse loss: 185.73289489746094, test mse loss: 187.5496063232422, test f1 score: 0.036966246304555216\n",
      "train mse loss: 187.3050537109375, test mse loss: 185.42486572265625, test f1 score: 0.2707243681791202\n",
      "train mse loss: 185.2004852294922, test mse loss: 187.01217651367188, test f1 score: 0.03666178742234245\n",
      "train mse loss: 186.76849365234375, test mse loss: 184.8918914794922, test f1 score: 0.27070127216560047\n",
      "train mse loss: 184.66796875, test mse loss: 186.46922302246094, test f1 score: 0.03636866813590327\n",
      "train mse loss: 186.2262725830078, test mse loss: 184.35562133789062, test f1 score: 0.2708151268390845\n",
      "train mse loss: 184.1324920654297, test mse loss: 185.93016052246094, test f1 score: 0.036105642435273574\n",
      "train mse loss: 185.6880645751953, test mse loss: 183.822021484375, test f1 score: 0.27096452701877466\n",
      "train mse loss: 183.59963989257812, test mse loss: 185.39039611816406, test f1 score: 0.035827471331941314\n",
      "train mse loss: 185.14920043945312, test mse loss: 183.28500366210938, test f1 score: 0.2711264459542656\n",
      "train mse loss: 183.06332397460938, test mse loss: 184.8497314453125, test f1 score: 0.035584974932302005\n",
      "train mse loss: 184.60943603515625, test mse loss: 182.74583435058594, test f1 score: 0.27124007447364357\n",
      "train mse loss: 182.52505493164062, test mse loss: 184.30941772460938, test f1 score: 0.03534255008947267\n",
      "train mse loss: 184.06988525390625, test mse loss: 182.20957946777344, test f1 score: 0.27132834815612356\n",
      "train mse loss: 181.98959350585938, test mse loss: 183.7740936279297, test f1 score: 0.03502406465981168\n",
      "train mse loss: 183.5352783203125, test mse loss: 181.67897033691406, test f1 score: 0.27142287076813937\n",
      "train mse loss: 181.4596405029297, test mse loss: 183.24246215820312, test f1 score: 0.03475651472969037\n",
      "train mse loss: 183.00430297851562, test mse loss: 181.14939880371094, test f1 score: 0.27157160257826296\n",
      "train mse loss: 180.9307861328125, test mse loss: 182.71681213378906, test f1 score: 0.034510920212135074\n",
      "train mse loss: 182.4791717529297, test mse loss: 180.625732421875, test f1 score: 0.2716497650259708\n",
      "train mse loss: 180.4082489013672, test mse loss: 182.19815063476562, test f1 score: 0.03426680365250355\n",
      "train mse loss: 181.96099853515625, test mse loss: 180.1092987060547, test f1 score: 0.271774395427631\n",
      "train mse loss: 179.89309692382812, test mse loss: 181.6884002685547, test f1 score: 0.03402641372455227\n",
      "train mse loss: 181.4513397216797, test mse loss: 179.5979461669922, test f1 score: 0.2718584545604712\n",
      "train mse loss: 179.38351440429688, test mse loss: 181.18138122558594, test f1 score: 0.03380798017684696\n",
      "train mse loss: 180.94406127929688, test mse loss: 179.08885192871094, test f1 score: 0.27187663355985364\n",
      "train mse loss: 178.87640380859375, test mse loss: 180.66824340820312, test f1 score: 0.033504524333577895\n",
      "train mse loss: 180.43077087402344, test mse loss: 178.5780029296875, test f1 score: 0.27186566009869423\n",
      "train mse loss: 178.36790466308594, test mse loss: 180.15359497070312, test f1 score: 0.03334817135536836\n",
      "train mse loss: 179.91537475585938, test mse loss: 178.0714874267578, test f1 score: 0.2718330335300493\n",
      "train mse loss: 177.8631591796875, test mse loss: 179.6559295654297, test f1 score: 0.03306566216317289\n",
      "train mse loss: 179.41688537597656, test mse loss: 177.57772827148438, test f1 score: 0.27193295627501457\n",
      "train mse loss: 177.37094116210938, test mse loss: 179.17164611816406, test f1 score: 0.03291926310920024\n",
      "train mse loss: 178.931884765625, test mse loss: 177.0946807861328, test f1 score: 0.2719636069672975\n",
      "train mse loss: 176.8894805908203, test mse loss: 178.69676208496094, test f1 score: 0.03266817303242316\n",
      "train mse loss: 178.45639038085938, test mse loss: 176.61669921875, test f1 score: 0.2718969770077496\n",
      "train mse loss: 176.4126739501953, test mse loss: 178.22683715820312, test f1 score: 0.032421941502945285\n",
      "train mse loss: 177.98594665527344, test mse loss: 176.15235900878906, test f1 score: 0.27204397831330773\n",
      "train mse loss: 175.94935607910156, test mse loss: 177.76641845703125, test f1 score: 0.03217815878510755\n",
      "train mse loss: 177.525146484375, test mse loss: 175.70028686523438, test f1 score: 0.27202315262600985\n",
      "train mse loss: 175.49798583984375, test mse loss: 177.31971740722656, test f1 score: 0.03194905605061669\n",
      "train mse loss: 177.0787353515625, test mse loss: 175.2550048828125, test f1 score: 0.2720838489120341\n",
      "train mse loss: 175.05372619628906, test mse loss: 176.87808227539062, test f1 score: 0.03165129009703439\n",
      "train mse loss: 176.63787841796875, test mse loss: 174.81924438476562, test f1 score: 0.2720779698232038\n",
      "train mse loss: 174.61965942382812, test mse loss: 176.44961547851562, test f1 score: 0.03136944414109425\n",
      "train mse loss: 176.21014404296875, test mse loss: 174.39877319335938, test f1 score: 0.2721124549609905\n",
      "train mse loss: 174.2012939453125, test mse loss: 176.0448455810547, test f1 score: 0.031059739461508258\n",
      "train mse loss: 175.80540466308594, test mse loss: 174.00169372558594, test f1 score: 0.2723114573104652\n",
      "train mse loss: 173.8065185546875, test mse loss: 175.6582794189453, test f1 score: 0.030808650199856517\n",
      "train mse loss: 175.4187774658203, test mse loss: 173.61668395996094, test f1 score: 0.27245695882264515\n",
      "train mse loss: 173.42401123046875, test mse loss: 175.27882385253906, test f1 score: 0.03054635450316026\n",
      "train mse loss: 175.03892517089844, test mse loss: 173.23574829101562, test f1 score: 0.2726092898789858\n",
      "train mse loss: 173.04502868652344, test mse loss: 174.9075927734375, test f1 score: 0.030379625607541205\n",
      "train mse loss: 174.66726684570312, test mse loss: 172.86172485351562, test f1 score: 0.2727652662023872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss: 172.67330932617188, test mse loss: 174.53619384765625, test f1 score: 0.030178270139666046\n",
      "train mse loss: 174.29507446289062, test mse loss: 172.48812866210938, test f1 score: 0.2727741700940729\n",
      "train mse loss: 172.30148315429688, test mse loss: 174.17269897460938, test f1 score: 0.03001092364747095\n",
      "train mse loss: 173.93096923828125, test mse loss: 172.13076782226562, test f1 score: 0.2728333363248707\n",
      "train mse loss: 171.94613647460938, test mse loss: 173.8280792236328, test f1 score: 0.029793882249753312\n",
      "train mse loss: 173.58506774902344, test mse loss: 171.79026794433594, test f1 score: 0.2729228228471187\n",
      "train mse loss: 171.607666015625, test mse loss: 173.4956512451172, test f1 score: 0.029542229139100085\n",
      "train mse loss: 173.25135803222656, test mse loss: 171.45809936523438, test f1 score: 0.27319978705292036\n",
      "train mse loss: 171.277099609375, test mse loss: 173.16949462890625, test f1 score: 0.029226826933961777\n",
      "train mse loss: 172.924072265625, test mse loss: 171.1241455078125, test f1 score: 0.27334872467735477\n",
      "train mse loss: 170.94485473632812, test mse loss: 172.8504180908203, test f1 score: 0.029035845197073078\n",
      "train mse loss: 172.6042938232422, test mse loss: 170.80018615722656, test f1 score: 0.2734957219554712\n",
      "train mse loss: 170.62252807617188, test mse loss: 172.54420471191406, test f1 score: 0.028837701225207405\n",
      "train mse loss: 172.29763793945312, test mse loss: 170.48199462890625, test f1 score: 0.27358390682901007\n",
      "train mse loss: 170.3061981201172, test mse loss: 172.2313690185547, test f1 score: 0.028679302324782444\n",
      "train mse loss: 171.98463439941406, test mse loss: 170.1592254638672, test f1 score: 0.2737929777245676\n",
      "train mse loss: 169.985107421875, test mse loss: 171.90884399414062, test f1 score: 0.028440808469682385\n",
      "train mse loss: 171.66207885742188, test mse loss: 169.8277587890625, test f1 score: 0.2740453893987827\n",
      "train mse loss: 169.6553955078125, test mse loss: 171.5787353515625, test f1 score: 0.02824825726754683\n",
      "train mse loss: 171.33216857910156, test mse loss: 169.4901885986328, test f1 score: 0.27418585232017184\n",
      "train mse loss: 169.3196563720703, test mse loss: 171.2440643310547, test f1 score: 0.028029825992106502\n",
      "train mse loss: 170.9978790283203, test mse loss: 169.1405487060547, test f1 score: 0.2741892542996697\n",
      "train mse loss: 168.97198486328125, test mse loss: 170.89743041992188, test f1 score: 0.027782941893371344\n",
      "train mse loss: 170.65138244628906, test mse loss: 168.78953552246094, test f1 score: 0.2743277994643468\n",
      "train mse loss: 168.62281799316406, test mse loss: 170.54971313476562, test f1 score: 0.027514372022692125\n",
      "train mse loss: 170.3037109375, test mse loss: 168.4357452392578, test f1 score: 0.274448689415775\n",
      "train mse loss: 168.2705078125, test mse loss: 170.20326232910156, test f1 score: 0.027338258400639522\n",
      "train mse loss: 169.95742797851562, test mse loss: 168.08810424804688, test f1 score: 0.2745358072874177\n",
      "train mse loss: 167.92408752441406, test mse loss: 169.8626251220703, test f1 score: 0.027175336761846983\n",
      "train mse loss: 169.6171112060547, test mse loss: 167.74732971191406, test f1 score: 0.2747242976356413\n",
      "train mse loss: 167.5845184326172, test mse loss: 169.5288543701172, test f1 score: 0.026943898486259093\n",
      "train mse loss: 169.28370666503906, test mse loss: 167.4102783203125, test f1 score: 0.2747793700702847\n",
      "train mse loss: 167.24856567382812, test mse loss: 169.19781494140625, test f1 score: 0.0267260886362382\n",
      "train mse loss: 168.9530487060547, test mse loss: 167.07797241210938, test f1 score: 0.27493076881704204\n",
      "train mse loss: 166.91741943359375, test mse loss: 168.86659240722656, test f1 score: 0.026520823988130156\n",
      "train mse loss: 168.6220245361328, test mse loss: 166.7486114501953, test f1 score: 0.2750349774370899\n",
      "train mse loss: 166.5891571044922, test mse loss: 168.5402374267578, test f1 score: 0.02633077780731035\n",
      "train mse loss: 168.29603576660156, test mse loss: 166.42279052734375, test f1 score: 0.2750903049643057\n",
      "train mse loss: 166.26426696777344, test mse loss: 168.21080017089844, test f1 score: 0.02619429913157577\n",
      "train mse loss: 167.96713256835938, test mse loss: 166.0945587158203, test f1 score: 0.27507377061063215\n",
      "train mse loss: 165.9368438720703, test mse loss: 167.87298583984375, test f1 score: 0.025976448480619568\n",
      "train mse loss: 167.62989807128906, test mse loss: 165.75274658203125, test f1 score: 0.2749508205378715\n",
      "train mse loss: 165.59608459472656, test mse loss: 167.5213623046875, test f1 score: 0.025899986524820246\n",
      "train mse loss: 167.27938842773438, test mse loss: 165.39889526367188, test f1 score: 0.27486792572624313\n",
      "train mse loss: 165.24343872070312, test mse loss: 167.1486053466797, test f1 score: 0.025715026354445693\n",
      "train mse loss: 166.90806579589844, test mse loss: 165.0218963623047, test f1 score: 0.27490348718397273\n",
      "train mse loss: 164.86749267578125, test mse loss: 166.7557373046875, test f1 score: 0.025597765208612795\n",
      "train mse loss: 166.51644897460938, test mse loss: 164.6262664794922, test f1 score: 0.2748547488556574\n",
      "train mse loss: 164.4729766845703, test mse loss: 166.3408203125, test f1 score: 0.025479733444916677\n",
      "train mse loss: 166.1025848388672, test mse loss: 164.21200561523438, test f1 score: 0.2748895300149512\n",
      "train mse loss: 164.05992126464844, test mse loss: 165.9137420654297, test f1 score: 0.025389841296196366\n",
      "train mse loss: 165.676513671875, test mse loss: 163.78475952148438, test f1 score: 0.2749792137388178\n",
      "train mse loss: 163.63385009765625, test mse loss: 165.47373962402344, test f1 score: 0.025395024097594393\n",
      "train mse loss: 165.23753356933594, test mse loss: 163.34939575195312, test f1 score: 0.27488516904534765\n",
      "train mse loss: 163.19952392578125, test mse loss: 165.03941345214844, test f1 score: 0.025296480986112885\n",
      "train mse loss: 164.80418395996094, test mse loss: 162.92555236816406, test f1 score: 0.27496150689120535\n",
      "train mse loss: 162.7765655517578, test mse loss: 164.61843872070312, test f1 score: 0.0252396066608748\n",
      "train mse loss: 164.3837432861328, test mse loss: 162.5117645263672, test f1 score: 0.2750059147416871\n",
      "train mse loss: 162.3638458251953, test mse loss: 164.21290588378906, test f1 score: 0.025045788021368896\n",
      "train mse loss: 163.97817993164062, test mse loss: 162.11962890625, test f1 score: 0.2750119229494548\n",
      "train mse loss: 161.97267150878906, test mse loss: 163.835205078125, test f1 score: 0.024750709167044777\n",
      "train mse loss: 163.60031127929688, test mse loss: 161.75315856933594, test f1 score: 0.27497924106690785\n",
      "train mse loss: 161.6072235107422, test mse loss: 163.48001098632812, test f1 score: 0.02444897973326496\n",
      "train mse loss: 163.24473571777344, test mse loss: 161.41030883789062, test f1 score: 0.2749814285849596\n",
      "train mse loss: 161.26544189453125, test mse loss: 163.14511108398438, test f1 score: 0.024247717678374615\n",
      "train mse loss: 162.90968322753906, test mse loss: 161.08810424804688, test f1 score: 0.2749759370975395\n",
      "train mse loss: 160.94390869140625, test mse loss: 162.84368896484375, test f1 score: 0.02402135848271558\n",
      "train mse loss: 162.6082000732422, test mse loss: 160.7989044189453, test f1 score: 0.2750812269099016\n",
      "train mse loss: 160.65524291992188, test mse loss: 162.5757293701172, test f1 score: 0.023827278245035985\n",
      "train mse loss: 162.3401641845703, test mse loss: 160.5377197265625, test f1 score: 0.27521805803280114\n",
      "train mse loss: 160.3946075439453, test mse loss: 162.3327178955078, test f1 score: 0.023622402420532894\n",
      "train mse loss: 162.0972137451172, test mse loss: 160.2993927001953, test f1 score: 0.2753306422857391\n",
      "train mse loss: 160.15664672851562, test mse loss: 162.11328125, test f1 score: 0.023395466694435766\n",
      "train mse loss: 161.8776397705078, test mse loss: 160.083251953125, test f1 score: 0.2755231037489102\n",
      "train mse loss: 159.94081115722656, test mse loss: 161.91159057617188, test f1 score: 0.023217615662688255\n",
      "train mse loss: 161.6759490966797, test mse loss: 159.8775634765625, test f1 score: 0.2756479566306392\n",
      "train mse loss: 159.73533630371094, test mse loss: 161.70913696289062, test f1 score: 0.023198213063671765\n",
      "train mse loss: 161.4735870361328, test mse loss: 159.66705322265625, test f1 score: 0.27564970517580256\n",
      "train mse loss: 159.5250244140625, test mse loss: 161.50132751464844, test f1 score: 0.023053693490824045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss: 161.2657928466797, test mse loss: 159.4492645263672, test f1 score: 0.27577915371037287\n",
      "train mse loss: 159.30726623535156, test mse loss: 161.2871856689453, test f1 score: 0.022876771385261518\n",
      "train mse loss: 161.05172729492188, test mse loss: 159.22579956054688, test f1 score: 0.27589328570783894\n",
      "train mse loss: 159.08399963378906, test mse loss: 161.0676727294922, test f1 score: 0.022728142337861107\n",
      "train mse loss: 160.83267211914062, test mse loss: 159.00021362304688, test f1 score: 0.27603946354331366\n",
      "train mse loss: 158.85841369628906, test mse loss: 160.84103393554688, test f1 score: 0.022591634970403292\n",
      "train mse loss: 160.60646057128906, test mse loss: 158.76614379882812, test f1 score: 0.27621865402983886\n",
      "train mse loss: 158.62428283691406, test mse loss: 160.6016845703125, test f1 score: 0.022425833223095614\n",
      "train mse loss: 160.36721801757812, test mse loss: 158.5098114013672, test f1 score: 0.2762911268390273\n",
      "train mse loss: 158.36781311035156, test mse loss: 160.33480834960938, test f1 score: 0.022265091790400312\n",
      "train mse loss: 160.1007537841797, test mse loss: 158.22865295410156, test f1 score: 0.2762866255254302\n",
      "train mse loss: 158.08645629882812, test mse loss: 160.04025268554688, test f1 score: 0.02220093693944724\n",
      "train mse loss: 159.8065948486328, test mse loss: 157.9269256591797, test f1 score: 0.27641318560319317\n",
      "train mse loss: 157.784423828125, test mse loss: 159.72409057617188, test f1 score: 0.022044192926762123\n",
      "train mse loss: 159.49069213867188, test mse loss: 157.6034698486328, test f1 score: 0.2764642691168947\n",
      "train mse loss: 157.4604949951172, test mse loss: 159.3873291015625, test f1 score: 0.02188371444506414\n",
      "train mse loss: 159.15444946289062, test mse loss: 157.26307678222656, test f1 score: 0.27660574167175683\n",
      "train mse loss: 157.1194610595703, test mse loss: 159.03565979003906, test f1 score: 0.021525927372665\n",
      "train mse loss: 158.8030242919922, test mse loss: 156.9125213623047, test f1 score: 0.2765829874972825\n",
      "train mse loss: 156.76815795898438, test mse loss: 158.67637634277344, test f1 score: 0.021418953331798427\n",
      "train mse loss: 158.44384765625, test mse loss: 156.55870056152344, test f1 score: 0.2765320607731664\n",
      "train mse loss: 156.41355895996094, test mse loss: 158.31642150878906, test f1 score: 0.021332868108862525\n",
      "train mse loss: 158.08419799804688, test mse loss: 156.20237731933594, test f1 score: 0.2765233598063897\n",
      "train mse loss: 156.056396484375, test mse loss: 157.95594787597656, test f1 score: 0.021155711902618116\n",
      "train mse loss: 157.72401428222656, test mse loss: 155.84909057617188, test f1 score: 0.2765229390406233\n",
      "train mse loss: 155.7022705078125, test mse loss: 157.59481811523438, test f1 score: 0.021041094360302562\n",
      "train mse loss: 157.3634033203125, test mse loss: 155.4980010986328, test f1 score: 0.2766869623505754\n",
      "train mse loss: 155.3504638671875, test mse loss: 157.2357635498047, test f1 score: 0.02092752874305645\n",
      "train mse loss: 157.00486755371094, test mse loss: 155.15135192871094, test f1 score: 0.2767681742624795\n",
      "train mse loss: 155.00308227539062, test mse loss: 156.8845977783203, test f1 score: 0.02078502584159799\n",
      "train mse loss: 156.65423583984375, test mse loss: 154.8137969970703, test f1 score: 0.2767811450643897\n",
      "train mse loss: 154.6647491455078, test mse loss: 156.5463104248047, test f1 score: 0.02065082226041274\n",
      "train mse loss: 156.31689453125, test mse loss: 154.49337768554688, test f1 score: 0.2767015383232389\n",
      "train mse loss: 154.3436737060547, test mse loss: 156.22406005859375, test f1 score: 0.02055667934864254\n",
      "train mse loss: 155.99554443359375, test mse loss: 154.18069458007812, test f1 score: 0.2766492818562812\n",
      "train mse loss: 154.03005981445312, test mse loss: 155.91067504882812, test f1 score: 0.020405239674214974\n",
      "train mse loss: 155.68309020996094, test mse loss: 153.8780975341797, test f1 score: 0.27663939337968335\n",
      "train mse loss: 153.72689819335938, test mse loss: 155.61007690429688, test f1 score: 0.020235627985978354\n",
      "train mse loss: 155.3835906982422, test mse loss: 153.58726501464844, test f1 score: 0.27661605549153845\n",
      "train mse loss: 153.43536376953125, test mse loss: 155.31695556640625, test f1 score: 0.02013479124136581\n",
      "train mse loss: 155.0915069580078, test mse loss: 153.30133056640625, test f1 score: 0.27678507020618426\n",
      "train mse loss: 153.1489715576172, test mse loss: 155.03179931640625, test f1 score: 0.019910274386939084\n",
      "train mse loss: 154.80728149414062, test mse loss: 153.01792907714844, test f1 score: 0.27690110391478134\n",
      "train mse loss: 152.8654022216797, test mse loss: 154.74607849121094, test f1 score: 0.019727660348452046\n",
      "train mse loss: 154.5226287841797, test mse loss: 152.73573303222656, test f1 score: 0.276940808430065\n",
      "train mse loss: 152.58322143554688, test mse loss: 154.46217346191406, test f1 score: 0.01953615623327234\n",
      "train mse loss: 154.23985290527344, test mse loss: 152.45693969726562, test f1 score: 0.2770269693910917\n",
      "train mse loss: 152.30430603027344, test mse loss: 154.18258666992188, test f1 score: 0.019373171516958523\n",
      "train mse loss: 153.96136474609375, test mse loss: 152.1787109375, test f1 score: 0.2770360813364492\n",
      "train mse loss: 152.02603149414062, test mse loss: 153.9017791748047, test f1 score: 0.019175569526316525\n",
      "train mse loss: 153.6812744140625, test mse loss: 151.9004364013672, test f1 score: 0.27699061778826267\n",
      "train mse loss: 151.74774169921875, test mse loss: 153.6177520751953, test f1 score: 0.01919973111973924\n",
      "train mse loss: 153.39772033691406, test mse loss: 151.6163330078125, test f1 score: 0.2769527031274107\n",
      "train mse loss: 151.46353149414062, test mse loss: 153.3323516845703, test f1 score: 0.019082244895814726\n",
      "train mse loss: 153.11289978027344, test mse loss: 151.33189392089844, test f1 score: 0.2769301657351043\n",
      "train mse loss: 151.17874145507812, test mse loss: 153.04397583007812, test f1 score: 0.018980756497703602\n",
      "train mse loss: 152.8250274658203, test mse loss: 151.04983520507812, test f1 score: 0.2770490534229019\n",
      "train mse loss: 150.8963165283203, test mse loss: 152.75892639160156, test f1 score: 0.018853378188954304\n",
      "train mse loss: 152.54034423828125, test mse loss: 150.77146911621094, test f1 score: 0.27699590528291756\n",
      "train mse loss: 150.6174774169922, test mse loss: 152.47459411621094, test f1 score: 0.018800405169059946\n",
      "train mse loss: 152.25619506835938, test mse loss: 150.4925537109375, test f1 score: 0.27719308843983603\n",
      "train mse loss: 150.338134765625, test mse loss: 152.1856689453125, test f1 score: 0.018692571701017013\n",
      "train mse loss: 151.96763610839844, test mse loss: 150.2080841064453, test f1 score: 0.27711027404958777\n",
      "train mse loss: 150.05340576171875, test mse loss: 151.89715576171875, test f1 score: 0.01860533614786088\n",
      "train mse loss: 151.6792449951172, test mse loss: 149.92678833007812, test f1 score: 0.27714623584806225\n",
      "train mse loss: 149.77197265625, test mse loss: 151.60848999023438, test f1 score: 0.01851975264906121\n",
      "train mse loss: 151.39065551757812, test mse loss: 149.64183044433594, test f1 score: 0.2769824139068441\n",
      "train mse loss: 149.48687744140625, test mse loss: 151.30323791503906, test f1 score: 0.018516764372594623\n",
      "train mse loss: 151.0856475830078, test mse loss: 149.3373565673828, test f1 score: 0.27690301076047974\n",
      "train mse loss: 149.18252563476562, test mse loss: 150.97586059570312, test f1 score: 0.01854847482130513\n",
      "train mse loss: 150.75843811035156, test mse loss: 149.0056915283203, test f1 score: 0.276915570129261\n",
      "train mse loss: 148.85133361816406, test mse loss: 150.6285400390625, test f1 score: 0.018482251282807227\n",
      "train mse loss: 150.41114807128906, test mse loss: 148.65684509277344, test f1 score: 0.27688465468009116\n",
      "train mse loss: 148.50299072265625, test mse loss: 150.27223205566406, test f1 score: 0.018442982610099766\n",
      "train mse loss: 150.05494689941406, test mse loss: 148.30467224121094, test f1 score: 0.2767716345908381\n",
      "train mse loss: 148.1511993408203, test mse loss: 149.919189453125, test f1 score: 0.018299019745527063\n",
      "train mse loss: 149.70217895507812, test mse loss: 147.95301818847656, test f1 score: 0.27673699048376627\n",
      "train mse loss: 147.7999725341797, test mse loss: 149.57077026367188, test f1 score: 0.01825970924924503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss: 149.353759765625, test mse loss: 147.61378479003906, test f1 score: 0.27672015827654434\n",
      "train mse loss: 147.46133422851562, test mse loss: 149.24232482910156, test f1 score: 0.018116743762929866\n",
      "train mse loss: 149.0254669189453, test mse loss: 147.29859924316406, test f1 score: 0.2766003072683957\n",
      "train mse loss: 147.14642333984375, test mse loss: 148.93934631347656, test f1 score: 0.01805017372150458\n",
      "train mse loss: 148.72254943847656, test mse loss: 147.0063934326172, test f1 score: 0.27652785177902267\n",
      "train mse loss: 146.85458374023438, test mse loss: 148.6632537841797, test f1 score: 0.017878665425092678\n",
      "train mse loss: 148.44680786132812, test mse loss: 146.7299041748047, test f1 score: 0.27650248078205103\n",
      "train mse loss: 146.57850646972656, test mse loss: 148.4131622314453, test f1 score: 0.01772760501602654\n",
      "train mse loss: 148.19715881347656, test mse loss: 146.49026489257812, test f1 score: 0.2766691295995271\n",
      "train mse loss: 146.33895874023438, test mse loss: 148.19158935546875, test f1 score: 0.017604668330579675\n",
      "train mse loss: 147.97628784179688, test mse loss: 146.27493286132812, test f1 score: 0.2766373339212707\n",
      "train mse loss: 146.1234893798828, test mse loss: 147.99517822265625, test f1 score: 0.017475755466008425\n",
      "train mse loss: 147.78038024902344, test mse loss: 146.07952880859375, test f1 score: 0.27676783238329994\n",
      "train mse loss: 145.9276580810547, test mse loss: 147.81320190429688, test f1 score: 0.017270428172957535\n",
      "train mse loss: 147.5989532470703, test mse loss: 145.89590454101562, test f1 score: 0.27692581443971587\n",
      "train mse loss: 145.74378967285156, test mse loss: 147.63841247558594, test f1 score: 0.017252236563906096\n",
      "train mse loss: 147.42465209960938, test mse loss: 145.718994140625, test f1 score: 0.27692490370843137\n",
      "train mse loss: 145.56671142578125, test mse loss: 147.47596740722656, test f1 score: 0.017137327351104074\n",
      "train mse loss: 147.26254272460938, test mse loss: 145.54568481445312, test f1 score: 0.2770900316766015\n",
      "train mse loss: 145.3933868408203, test mse loss: 147.29661560058594, test f1 score: 0.017035655203970292\n",
      "train mse loss: 147.08251953125, test mse loss: 145.36471557617188, test f1 score: 0.27706307665076624\n",
      "train mse loss: 145.212646484375, test mse loss: 147.1221923828125, test f1 score: 0.016954582419478056\n",
      "train mse loss: 146.9071502685547, test mse loss: 145.1890106201172, test f1 score: 0.2770079802481784\n",
      "train mse loss: 145.03717041015625, test mse loss: 146.9600830078125, test f1 score: 0.01683856178540869\n",
      "train mse loss: 146.74395751953125, test mse loss: 145.0200958251953, test f1 score: 0.2769922467215155\n",
      "train mse loss: 144.8688201904297, test mse loss: 146.781982421875, test f1 score: 0.01666631446221903\n",
      "train mse loss: 146.5644073486328, test mse loss: 144.84083557128906, test f1 score: 0.2770121957588663\n",
      "train mse loss: 144.6905059814453, test mse loss: 146.60389709472656, test f1 score: 0.01656403680583933\n",
      "train mse loss: 146.38497924804688, test mse loss: 144.65728759765625, test f1 score: 0.2771331812593459\n",
      "train mse loss: 144.5079803466797, test mse loss: 146.43150329589844, test f1 score: 0.01637218349813584\n",
      "train mse loss: 146.2117156982422, test mse loss: 144.4803466796875, test f1 score: 0.2772306247513885\n",
      "train mse loss: 144.33238220214844, test mse loss: 146.24745178222656, test f1 score: 0.016221875209294617\n",
      "train mse loss: 146.0263214111328, test mse loss: 144.29591369628906, test f1 score: 0.277122397822122\n",
      "train mse loss: 144.14976501464844, test mse loss: 146.06576538085938, test f1 score: 0.016070912283423475\n",
      "train mse loss: 145.84329223632812, test mse loss: 144.11802673339844, test f1 score: 0.27716320563760405\n",
      "train mse loss: 143.97390747070312, test mse loss: 145.8987579345703, test f1 score: 0.015914221218961622\n",
      "train mse loss: 145.67510986328125, test mse loss: 143.9429473876953, test f1 score: 0.277226920271256\n",
      "train mse loss: 143.80062866210938, test mse loss: 145.71322631835938, test f1 score: 0.015790977692950858\n",
      "train mse loss: 145.48780822753906, test mse loss: 143.74969482421875, test f1 score: 0.27723293048363007\n",
      "train mse loss: 143.60923767089844, test mse loss: 145.52090454101562, test f1 score: 0.015638618071213577\n",
      "train mse loss: 145.29409790039062, test mse loss: 143.5413818359375, test f1 score: 0.27713939466929616\n",
      "train mse loss: 143.4025421142578, test mse loss: 145.31793212890625, test f1 score: 0.015535392249243878\n",
      "train mse loss: 145.0903778076172, test mse loss: 143.32376098632812, test f1 score: 0.2770103657184741\n",
      "train mse loss: 143.186279296875, test mse loss: 145.0852813720703, test f1 score: 0.01547383319744315\n",
      "train mse loss: 144.85693359375, test mse loss: 143.08554077148438, test f1 score: 0.2769917936304308\n",
      "train mse loss: 142.94923400878906, test mse loss: 144.83786010742188, test f1 score: 0.015488771699458528\n",
      "train mse loss: 144.60948181152344, test mse loss: 142.83619689941406, test f1 score: 0.2769725857989867\n",
      "train mse loss: 142.70074462890625, test mse loss: 144.58889770507812, test f1 score: 0.015447940862910117\n",
      "train mse loss: 144.36105346679688, test mse loss: 142.5843505859375, test f1 score: 0.27697411915982795\n",
      "train mse loss: 142.44960021972656, test mse loss: 144.3175048828125, test f1 score: 0.01544218887908208\n",
      "train mse loss: 144.09010314941406, test mse loss: 142.31661987304688, test f1 score: 0.27704821400357316\n",
      "train mse loss: 142.1822052001953, test mse loss: 144.0364990234375, test f1 score: 0.015366200713935154\n",
      "train mse loss: 143.81044006347656, test mse loss: 142.0357208251953, test f1 score: 0.27700007153848843\n",
      "train mse loss: 141.90089416503906, test mse loss: 143.753173828125, test f1 score: 0.01527558554645706\n",
      "train mse loss: 143.52822875976562, test mse loss: 141.7593536376953, test f1 score: 0.27700061935373643\n",
      "train mse loss: 141.62417602539062, test mse loss: 143.4822235107422, test f1 score: 0.015199457565826647\n",
      "train mse loss: 143.2583770751953, test mse loss: 141.50039672851562, test f1 score: 0.27687266547252976\n",
      "train mse loss: 141.3649139404297, test mse loss: 143.23109436035156, test f1 score: 0.015199564919517173\n",
      "train mse loss: 143.00823974609375, test mse loss: 141.25897216796875, test f1 score: 0.2767931248870636\n",
      "train mse loss: 141.12307739257812, test mse loss: 142.99876403808594, test f1 score: 0.015137869042951847\n",
      "train mse loss: 142.77708435058594, test mse loss: 141.03607177734375, test f1 score: 0.27669958773231296\n",
      "train mse loss: 140.89964294433594, test mse loss: 142.78396606445312, test f1 score: 0.015103883351112304\n",
      "train mse loss: 142.56370544433594, test mse loss: 140.83065795898438, test f1 score: 0.27659404431111223\n",
      "train mse loss: 140.69366455078125, test mse loss: 142.5887451171875, test f1 score: 0.015112389121058079\n",
      "train mse loss: 142.36988830566406, test mse loss: 140.64012145996094, test f1 score: 0.27656171837121063\n",
      "train mse loss: 140.50303649902344, test mse loss: 142.41415405273438, test f1 score: 0.015050450806930273\n",
      "train mse loss: 142.19674682617188, test mse loss: 140.47250366210938, test f1 score: 0.2765152332206544\n",
      "train mse loss: 140.33511352539062, test mse loss: 142.24737548828125, test f1 score: 0.014989240396744912\n",
      "train mse loss: 142.03070068359375, test mse loss: 140.30958557128906, test f1 score: 0.2766176674738936\n",
      "train mse loss: 140.17196655273438, test mse loss: 142.09388732910156, test f1 score: 0.0148571711295903\n",
      "train mse loss: 141.8780517578125, test mse loss: 140.15342712402344, test f1 score: 0.2765612452900117\n",
      "train mse loss: 140.01553344726562, test mse loss: 141.95468139648438, test f1 score: 0.014824502491958573\n",
      "train mse loss: 141.74017333984375, test mse loss: 140.01089477539062, test f1 score: 0.27654487370697045\n",
      "train mse loss: 139.8728485107422, test mse loss: 141.80783081054688, test f1 score: 0.014776792658267226\n",
      "train mse loss: 141.59408569335938, test mse loss: 139.86146545410156, test f1 score: 0.2764672766528708\n",
      "train mse loss: 139.7235565185547, test mse loss: 141.66331481933594, test f1 score: 0.014743005027470779\n",
      "train mse loss: 141.45016479492188, test mse loss: 139.70968627929688, test f1 score: 0.2765683433637962\n",
      "train mse loss: 139.5719451904297, test mse loss: 141.52288818359375, test f1 score: 0.014702086508236777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss: 141.3105926513672, test mse loss: 139.5596923828125, test f1 score: 0.27667162421763647\n",
      "train mse loss: 139.42227172851562, test mse loss: 141.3666229248047, test f1 score: 0.014619138552938681\n",
      "train mse loss: 141.15443420410156, test mse loss: 139.3968505859375, test f1 score: 0.2767771571069225\n",
      "train mse loss: 139.25987243652344, test mse loss: 141.20327758789062, test f1 score: 0.014564926750939046\n",
      "train mse loss: 140.9914093017578, test mse loss: 139.23313903808594, test f1 score: 0.276869004724033\n",
      "train mse loss: 139.09649658203125, test mse loss: 141.0392608642578, test f1 score: 0.014488754943367928\n",
      "train mse loss: 140.82766723632812, test mse loss: 139.06932067871094, test f1 score: 0.2769285289075335\n",
      "train mse loss: 138.9332275390625, test mse loss: 140.87814331054688, test f1 score: 0.014357384960480044\n",
      "train mse loss: 140.66673278808594, test mse loss: 138.90733337402344, test f1 score: 0.2771114897722587\n",
      "train mse loss: 138.7718505859375, test mse loss: 140.7255859375, test f1 score: 0.01430942178471468\n",
      "train mse loss: 140.5142822265625, test mse loss: 138.7513885498047, test f1 score: 0.27730213904993084\n",
      "train mse loss: 138.6167755126953, test mse loss: 140.56369018554688, test f1 score: 0.014233389365655137\n",
      "train mse loss: 140.35218811035156, test mse loss: 138.58599853515625, test f1 score: 0.27731344121748736\n",
      "train mse loss: 138.45260620117188, test mse loss: 140.3981475830078, test f1 score: 0.014101257220523276\n",
      "train mse loss: 140.18594360351562, test mse loss: 138.41839599609375, test f1 score: 0.2774009182048159\n",
      "train mse loss: 138.28628540039062, test mse loss: 140.2335968017578, test f1 score: 0.013955019665178649\n",
      "train mse loss: 140.020751953125, test mse loss: 138.25106811523438, test f1 score: 0.2773869566644421\n",
      "train mse loss: 138.1203155517578, test mse loss: 140.06149291992188, test f1 score: 0.013767900395189731\n",
      "train mse loss: 139.84751892089844, test mse loss: 138.075439453125, test f1 score: 0.2773439578358314\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-defee5bdba80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mse_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mop1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, y_binary: y_train_binary.reshape(-1, 1)})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mtest_mse_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, y_binary: y_test_binary.reshape(-1, 1)})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0my_test_pred_binary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1102\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    \n",
    "    feature_len = X_test_scaled.shape[1]\n",
    "    num_hidden_units_layer_1 = 64\n",
    "    num_hidden_units_layer_2 = 64\n",
    "\n",
    "    X = tf.placeholder(\"float\", [None, feature_len], name=\"myInput\")\n",
    "    y = tf.placeholder(\"float\", [None, 1])\n",
    "#     y_binary = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "    W1 = tf.Variable(tf.random_normal([feature_len, num_hidden_units_layer_1]))\n",
    "    b1 = tf.Variable(tf.zeros([1, num_hidden_units_layer_1]) + 0.1)\n",
    "    Z1 = tf.matmul(X, W1) + b1\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "\n",
    "    W2 = tf.Variable(tf.random_normal([num_hidden_units_layer_1, num_hidden_units_layer_2]))\n",
    "    b2 = tf.Variable(tf.zeros([1, num_hidden_units_layer_2]) + 0.1)\n",
    "    Z2 = tf.matmul(A1, W2) + b2\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "#     A2 = tf.nn.sigmoid(Z2)\n",
    "\n",
    "\n",
    "    W3 = tf.Variable(tf.random_normal([num_hidden_units_layer_2, 1]))\n",
    "    b3 = tf.Variable(tf.zeros([1, 1]) + 0.1)\n",
    "    Z3 = tf.add(tf.matmul(A2, W3), b3)\n",
    "    A3 = Z3\n",
    "    tf.identity(A3, name=\"myOutput\")\n",
    "    \n",
    "\n",
    "    mse_loss = tf.reduce_mean((A3 - y) ** 2)\n",
    "    op1 = tf.train.AdadeltaOptimizer(learning_rate=20).minimize(mse_loss)\n",
    "\n",
    "\n",
    "#     threshold = tf.constant(-103.0)\n",
    "#     output_prob = tf.nn.sigmoid(threshold - A3)\n",
    "#     cross_entropy = -tf.reduce_mean(y_binary * tf.log(tf.clip_by_value(output_prob, 1e-10, 1.0)))\n",
    "#     op2 = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "    \n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_epoch = 1000\n",
    "    summary_writer = tf.summary.FileWriter('./log/', sess.graph)\n",
    "    for i in range(n_epoch):\n",
    "        _, train_mse_loss = sess.run([op1, mse_loss], feed_dict={X: X_train_scaled, y: y_train.reshape(-1, 1)})#, y_binary: y_train_binary.reshape(-1, 1)})\n",
    "        test_mse_loss, y_test_pred = sess.run([mse_loss, A3], feed_dict={X: X_test_scaled, y: y_test.reshape(-1, 1)})#, y_binary: y_test_binary.reshape(-1, 1)})\n",
    "\n",
    "        y_test_pred_binary = copy.copy(y_test_pred)\n",
    "        y_test_pred_binary[y_test_pred>=-103] = 0\n",
    "        y_test_pred_binary[y_test_pred<-103] = 1\n",
    "        test_f1_score = f1_score(y_test_binary, y_test_pred_binary)\n",
    "        \n",
    "        print (\"train mse loss: {}, test mse loss: {}, test f1 score: {}\".format(train_mse_loss, test_mse_loss, test_f1_score))\n",
    "    \n",
    "    \n",
    "#     for i in range(5):\n",
    "#         _, train_cross_entropy_loss = sess.run([op2, cross_entropy], feed_dict={X: X_train_scaled, y: y_train.reshape(-1, 1), y_binary: y_train_binary.reshape(-1, 1)})\n",
    "#         test_mse_loss, test_cross_entropy_loss, y_test_pred = sess.run([mse_loss, cross_entropy, A3], feed_dict={X: X_test_scaled, y: y_test.reshape(-1, 1), y_binary: y_test_binary.reshape(-1, 1)})\n",
    "        \n",
    "#         y_test_pred_binary = copy.copy(y_test_pred)\n",
    "#         y_test_pred_binary[y_test_pred>=-103] = 0\n",
    "#         y_test_pred_binary[y_test_pred<-103] = 1\n",
    "#         test_f1_score = f1_score(y_test_binary, y_test_pred_binary)\n",
    "        \n",
    "#         print (\"test mse loss: {}, test cross entropy loss: {}, test f1 score: {}\".format(test_mse_loss, test_cross_entropy_loss, test_f1_score))\n",
    "        \n",
    "    tf.saved_model.simple_save(sess, \"./model/\", inputs={\"myInput\": X }, outputs={\"myOutput\": A3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error: 138.0754355711452\n",
      "precision : 0.24500736833083114\n",
      "recall : 0.31951410347475867\n",
      "f1 score: 0.2773439578358314\n"
     ]
    }
   ],
   "source": [
    "print (\"mean squared error: {}\".format(mean_squared_error(y_test, y_test_pred)))\n",
    "print (\"precision : {}\".format(precision_score(y_test_binary, y_test_pred_binary)))\n",
    "print (\"recall : {}\".format(recall_score(y_test_binary, y_test_pred_binary)))\n",
    "print (\"f1 score: {}\".format(f1_score(y_test_binary, y_test_pred_binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, [\"serve\"], \"./model\")\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    X = sess.graph.get_tensor_by_name('myInput:0')\n",
    "    y = sess.graph.get_tensor_by_name('myOutput:0')\n",
    "\n",
    "    y_test_pred = sess.run(y, feed_dict={X: X_test})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "486.083px",
    "left": "669px",
    "right": "20px",
    "top": "54px",
    "width": "518.467px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
